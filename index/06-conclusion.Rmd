# General Discussion {-}

In this thesis I investigated inference about absence in visual perception, and its relation with self-modeling and default-mode reasoning. In chapters \@ref(ch:termination) and \@ref(ch:MVS) I focused on visual search, and asked what people know about their visual search behaviour, and how this knowledge related to their ability to efficiently terminate a search in the absence of a target. In Chapter \@ref(ch:RC) I used reverse correlation to ask what information is incorporated into confidence judgments in decisions about the presence and absence of a stimulus. Then, in chapter \@ref(ch:fMRI) I used functional imaging to compare the neural processes governing metacognitive evaluation of decisions about stimulus type and stimulus presence or absence. Finally, in chapter \@ref(ch:asymmetry) I borrowed ideas from the visual search literature to ask at what cognitive level does the metacognitive asymmetry between judgments of presence and absence emerge. 

In what follows I evaluate my original proposal, that inference about absence critically relies on self-knowledge, in light of my findings. Specifically, I list observations that don't fit with this idea. Before concluding, I briefly describe two directions for future research that build on and extend my work here.


## What I didn't find

The theoretical proposal put forward in this thesis is that inference about absence is unique in that it requires relying on a self-model. In previous chapters I tried to make sense of my data in light of this proposal. However, some patterns that I expected to find were missing in the data, and some patterns that I did find were difficult to reconcile with this overarching idea. In the following, and following Charles Darwin's advice to make an effort to remember observations that don't fit with one's theory [@darwin1958autobiography, 123], I list some things that I thought I should find, but I didn't. 

### Chapter 1: no correlation with explicit metacognition

In Chapter \@ref(ch:termination), I show that participants can immediately recognize the absence of a salient target in a display, and that they can do so even before having experience with the task. Our interpretation of the results abscribes this 'absence pop-out' to pre-existing metacognitive knowledge of the parallel nature of feature search. We further show that even participants whose explicit metacognitive reports show no insight into the parallel nature of feature search exhibit the same pattern of search time in target-absent trials - a finding that we interpret as indicating a dissociation between explicit and implicit metacognitive knowledge.

A much stronger support for the proposal I put forward here would have been a correlation between explicit metacognitive knowledge of search efficiency and search slopes in target-absent trials, such that participants who rate feature searches as easier are also more likely to quit them earlier in the absence of a target. Instead, we found no correlation between explicit metacognition and behaviour on target-absent trials. A full dissociation between implicit and explicit metacognition is one possible interpretation for our results. An alternative interpretation is that the immediate recognition of target absence in these first trials is not at all dependent on metacognitive knowledge - explicit or implicit. In the discussion of Chapter 1 we list some alternative accounts, such as immediate recognition of absence via ensemble perception, and explain how they depend on implicit metacognitive knowledge, for example in the form of a firing threshold on neurons in the visual pathway. One concern is that a notion of self-modeling that encompasses the firing thresholds of visual neurons is too permissive to be scientifically useful. The visual system translates incoming sensory signals into beliefs about the external world. To do that, neurons down the visual stream implicitly represent a likelihood function going from world states into firing patterns, and invert this function to approximate a representation of the world state, given observed firing patterns. This likelihood function is a form of self-knowledge, in the sense that it is knowledge about how the brain responds to incoming signals. But its importance is not specific to the representation of absence (although representations of absence may be more sensitive to these internal models compared with other decisions).

In the pre-registration documents for Experiments [1](https://osf.io/ea385) and [2](https://osf.io/v6mnb) we focused on a contrast between blocks 1 and 3 (before and after experience with target-present trials), with the hypothesis that task experience will affect the search slope for target-absent trials. A learning affect between blocks 1 and 3 would have allowed us to further ask how generalizable this new knowledge is, and for how long is it retained in the system, giving us a better hold of this mental self-model. In section \@ref(failures) I expand on how focusing on model failures (such as mismatches between target-present and target-absent search efficiency) can be useful for understanding the structure of the mental self model.

### Chapter 3: no effect of confidence in signal presence

```{r RC-previous-trials, echo=FALSE, message=FALSE, include=FALSE}
# List of packages required for this analysis
pkg <- c("dplyr", "ggplot2", "knitr", "bookdown")
# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg)) {
  install.packages(new.pkg, repos = "https://cran.rstudio.com")
}
# Load packages

library("papaja")
r_refs("r-references.bib")
library('tidyverse')
library('broom')
library('cowplot')
library('MESS') # for AUCs
library('lsr') # for effect sizes
library('pwr') # for power calculations
library('brms') # for mixed effects modeling
library('BayesFactor') # for Bayesian t test
library('jsonlite') #parsing data from sort_trial
library('thesisdown')
library('knitr')
library('egg')
library('zoo') # for rollapply
library('RColorBrewer')
library('reticulate') # for python

e1=list()

e1$df <- read_csv('data/RC/RC.csv') %>%
  group_by(subj_id, detection) %>%
  mutate(confidence=confidence/1000,
         # in the original coding, 3 is right and 1 is left. 
         # changed to be 0 for right/up and 1 for left/down, to align 
         # with the coding of responses.
         direction = ifelse(direction==3,1,0)); 
 
e1$trial_df_unfiltered <- e1$df %>%
  group_by(subj_id, trial_id) %>%
  summarise(
    detection = detection[timepoint==1],
    direction = direction[timepoint==1],
    signal = signal[timepoint==1],
    response = response[timepoint==1],
    RT = RT[timepoint==1]-700, # stimulus duration
    confidence = confidence[timepoint==1],
    correct = correct[timepoint==1],
    trial_number = trial_number[timepoint==1],
    logRT = log(RT[timepoint==1]),
    conf_bi = ifelse(
        response==1, 
        as.numeric(confidence),
        -1*as.numeric(confidence)))%>%
  group_by(subj_id) %>%
  mutate(
    conf_discrete = ntile(confidence,20) %>%
      factor(levels=1:21))

e1$task_stats_unfiltered <- e1$trial_df_unfiltered %>%
  group_by(subj_id,detection) %>%
  summarise(acc=mean(correct),
            RT = median(RT),
            confidence=mean(confidence));

e1$trial_df <- e1$trial_df_unfiltered %>%
  filter(trial_number>300);

e1$detection_df <- e1$trial_df %>%
  filter(detection==1) %>%
  mutate(stimulus=signal);

e1$discrimination_df <- e1$trial_df %>%
  filter(detection==0) %>%
  mutate(stimulus = direction);

lcin = c(); # last confidence in no
lciy = c(); # last confidence in yes
tp = c(); # target prevalence
lt = c() # last target

for (subj in e1$detection$subj_id%>%unique()) {
  subj_df <- e1$detection_df%>%filter(subj_id==subj);

  for (i_r in seq(1,subj_df%>%nrow())) {
    
    if (i_r%%40==1) {
      last_conf_in_yes=NA;
      last_conf_in_no=NA;
      last_5_trials = c(NA,NA,NA,NA,NA);
      last_target = NA;
    } else if (subj_df$response[i_r]==0 & subj_df$correct[i_r]==1) {
      last_conf_in_no=subj_df$confidence[i_r]
    } else if (subj_df$response[i_r]==1 & subj_df$correct[i_r]==1) {
      last_conf_in_yes=subj_df$confidence[i_r]
    }
  
    last_5_trials = c(subj_df$signal[i_r],last_5_trials[1:4]);
    if (subj_df$stimulus[i_r]==1) {
      last_target=0
    } else {
      last_target= last_target+1;
    }
    lcin = c(lcin,last_conf_in_no);
    lciy = c(lciy,last_conf_in_yes);
    tp=c(tp,mean(last_5_trials));
    lt=c(lt,last_target)
  }
};

e1$detection_df <- e1$detection_df %>%
  ungroup() %>%
  mutate(lciy = lciy,
         lcin=lcin,
         tp=tp,
         lt=lt);

e1$effect_of_prev_conf_in_yes <- e1$detection_df %>%
  group_by(subj_id) %>%
  filter(response==0 & correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,lciy));


e1$effect_of_prev_conf_in_no <- e1$detection_df %>%
  group_by(subj_id) %>%
  filter(response==1 & correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,lcin));


e1$effect_target_prevalence <- e1$detection_df %>%
  group_by(subj_id,response) %>%
  filter(correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,tp)) %>%
  spread(response,correlation,sep='');

e1$effect_last_target <- e1$detection_df %>%
  group_by(subj_id,response) %>%
  filter(correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,lt)) %>%
  spread(response,correlation,sep='');


e2=list()

e2$df <- read_csv('data/RC/Flicker.csv') %>%
  group_by(s,task,trial_index) %>%
  mutate(side=c(rep(0,48),rep(1,48)),
         timepoint=rep(1:12,8), 
         eccentricity = rep(c(rep(1,12),rep(2,12),rep(3,12),rep(4,12)),2)) %>%
  rename(subj_id = s,
         trial_id = trial_index) %>%
  mutate(detection = ifelse(task=='detection',1,0),
         bright_side=ifelse(bright_side=='right',1,0),
         signal=signal_presence,
         detection=as.factor(detection),
         response=as.factor(response),
         correct=as.factor(correct),
         subj_id=as.factor(subj_id)) %>%
  ungroup() %>%
  dplyr::select(subj_id,detection,trial_id,
         RT,signal,correct,bright_side,
         response,conf_RT,confidence,
         luminance,side,timepoint,
         eccentricity,trial)
 
e2$trial_df <- e2$df %>%
  group_by(subj_id, trial_id) %>%
  summarise(
    detection = detection[side==1 & timepoint==1 & eccentricity == 1],
    bright_side = bright_side[side==1 & timepoint==1 & eccentricity == 1],
    signal = signal[side==1 & timepoint==1 & eccentricity == 1],
    response = response[side==1 & timepoint==1 & eccentricity == 1],
    RT = RT[side==1 & timepoint==1 & eccentricity == 1]-480, # stimulus duration
    confidence = confidence[side==1 & timepoint==1 & eccentricity == 1],
    correct = correct[side==1 & timepoint==1 & eccentricity == 1],
    trial_number = trial[side==1 & timepoint==1 & eccentricity == 1],
     conf_bi = ifelse(
        response==1, 
        as.numeric(confidence),
        -1*as.numeric(confidence)))%>%
  group_by(subj_id) %>%
  mutate(
    conf_discrete = ntile(confidence,20) %>%
      factor(levels=1:21),
    logRT=log(RT));

e2$detection_df <- e2$trial_df %>%
  filter(detection==1) %>%
  mutate(stimulus=signal);

e2$discrimination_df <- e2$trial_df %>%
  filter(detection==0) %>%
  mutate(stimulus = bright_side);


lcin = c(); # last confidence in no
lciy = c(); # last confidence in yes
tp = c(); # target prevalence
lt = c(); # last target

for (subj in e2$detection$subj_id%>%unique()) {
  subj_df <- e2$detection_df%>%filter(subj_id==subj);
  last_conf_in_no = NA;
  last_conf_in_yes = NA;
  last_5_trials = c(NA,NA,NA,NA,NA);
  last_target=NA
  for (i_r in seq(1,subj_df%>%nrow())) {
    
    if (subj_df$response[i_r]==0 & subj_df$correct[i_r]==1) {
      last_conf_in_no=subj_df$confidence[i_r]
    } else if (subj_df$response[i_r]==1 & subj_df$correct[i_r]==1) {
      last_conf_in_yes=subj_df$confidence[i_r]
    }
    
    last_5_trials = c(subj_df$signal[i_r],last_5_trials[1:4])
    if (subj_df$stimulus[i_r]==1) {
      last_target=0
    } else {
      last_target=last_target+1
    }
    lcin = c(lcin,last_conf_in_no);
    lciy = c(lciy,last_conf_in_yes);
    tp=c(tp,mean(last_5_trials));
    lt=c(lt, last_target)
  }
};

last_target=lt
e2$detection_df <- e2$detection_df %>%
  ungroup() %>%
  mutate(lciy = lciy,
         lcin=lcin,
         tp=tp) %>%
  mutate(lt=last_target)

e2$effect_of_prev_conf_in_yes <- e2$detection_df %>%
  group_by(subj_id) %>%
  filter(response==0 & correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,lciy));


e2$effect_of_prev_conf_in_no <- e2$detection_df %>%
  group_by(subj_id) %>%
  filter(response==1 & correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,lcin))

e2$effect_target_prevalence <- e2$detection_df %>%
  group_by(subj_id,response) %>%
  filter(correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,tp)) %>%
  spread(response,correlation,sep='');

e2$effect_last_target <- e2$detection_df %>%
  group_by(subj_id,response) %>%
  filter(correct==1) %>%
  drop_na() %>%
  summarise(correlation=cor(confidence,lt)) %>%
  spread(response,correlation,sep='');
```

In Chapter \@ref(ch:RC), I asked what drives confidence in decisions about target absence. Since decisions about target absence are based on the absence of perceptual evidence, I hypothesized that subjective confidence in such decisions may rely on other factors. For example, if participants are using a counterfactual heuristic, their confidence in previous 'target present' trials may inform their confidence in 'target absent' decisions  ("When a target was present it was highly visible, so I would have seen the target if it was present"). This effect should be stronger than the effect of previous confidence in target-absence decisions on confidence in presence, because confidence in presence can be based on perceptual evidence. To test this, I looked at the correlation between confidence in absence and confidence in the last target-presence decision. This correlation was not significantly different from 0 in Experiment 1 (`r apa_print(e1$effect_of_prev_conf_in_yes$correlation%>%t.test())$statistic`). In Experiment 2, this correlation was significantly higher 0 at the group level (`r apa_print(e2$effect_of_prev_conf_in_yes$correlation%>%t.test())$full_result`), but a similarly high correlation between confidence in 'yes' responses and in the last decision about target absence suggests that this was not specific to decisions about absence (`r apa_print(t.test(e2$effect_of_prev_conf_in_yes$correlation,e2$effect_of_prev_conf_in_no$correlation))$full_result`). 

Similarly, a counterfactual heuristic predicts lower confidence in absence when local target prevalence (for example, the number of targets presented in the last 5 trials) is low [@hsu2017absence]. To see this, compare two participants that are presented with random noise: one that hasn't seen a target for 4 trials in a row, and one that just saw a target in the previous trial. The first participant may doubt their perceptual sensitivity and give a low confidence rating, but the second can be more confident that they would not have missed a target. Contrary to this prediction, local target prevalence had no effect on confidence in 'no' responses in Experiment 2 (quantified as the distance in number of trials from the last encounter with a target; `r apa_print(e2$effect_last_target$response0%>%t.test())$statistic`). In Experiment 1, a significant correlation in the opposite direction was observed, such that participants were more confident in their 'no' responses when a target hasn't been observed for a longer series of trials (`r apa_print(e1$effect_last_target$response0%>%t.test())$statistic`). Overall, we found no evidence for higher susceptibility of confidence in absence to confidence and stimulus prevalence in previous trials.
 
 
### Chapter 4: only minor differences in brain activity between inference about absence and presence

In Chapter \@ref(ch:fMRI), we compared brain activity in discrimination and detection. Within detection, we compared decisions about signal presence and absence. Our [pre-registration document](https://github.com/matanmazor/detectionVsDiscrimination_fMRI/blob/master/protocol%20folder/docs/Confidence%20in%20Detection%20and%20Discrimination.pdf) largely focused on the behavioural differences between 'yes' and 'no' responses, and their possible neural underpinning, with a focus on the lateral prefrontal cortex and regions that have been associated with counterfactual reasoning ["I would have seen it if it was there"; @boorman2009green]. To our surprise, we found no significant difference in overall activity between 'yes' and 'no' responses (for an uncorrected map, see [here](https://identifiers.org/neurovault.image:305384)). A significant difference in the parametric modulation of confidence was found not in our pre-defined regions of interests, but in the [right temporo-parietal junction (rTPJ)](https://identifiers.org/neurovault.image:305379).

Given the reliable behavioural differences in reaction time, overall confidence, and metacognitive sensitivity, a similar profile of BOLD activation for 'yes' and 'no' responses was unexpected. In language comprehension, for example, the processing of negation shows distinct neurobiological markers that are overlapping with those of response inhibition [@papeo2020neurobiology]. In visual search, the right lateral prefrontal cortex was more engaged in target-absent trials [@vallesi2014monitoring], and the right temporo-parietal junction showed differential activation in visual search hit and miss trials [@shulman2007right]. To our surprise, despite the robust behavioural differences, BOLD activations for 'yes' and 'no' responses gave rise to indistinguishable baseline activation, differing only in the modulation of confidence. When focusing on the frontopolar cortex, confidence modulation was different between detection and discrimination, but remarkably similar for detection 'yes' and 'no' responses. Again, this is in contrast to our original hypothesis, that counterfactual reasoning should play a major role in decisions about target absence, more so than in decisions about target presence.


### Chapter 5: no metacognitive asymmetry between default-complying and default-violating signals

In Chapter \@ref(ch:asymmetry), I focused on three behavioural asymmetries between detection 'yes' (stimulus present) and 'no' (stimulus absent) responses: in reaction time, global confidence, and metacognitive sensitivity. Using stimulus pairs that generate asymmetries in visual search, I asked whether detection-like asymmetries would emerge in discrimination tasks that can be described as the detection of sub-stimulus presences: local stimulus features (such as the line that distinguishes a *Q* from an *O*), global features (such as the presence or absence of curvature), and expectation violations (such as the presence or absence of letter inversion). My reasoning was the following: if presence/absence asymmetries emerge because participants assume absence as default unless they have evidence for presence, similar asymmetries should emerge for other things that we take as default (e.g., letters are not mirrored, objects are not floating in space). This default-reasoning framework also provided a conceptual link to metacognitive asymmetries in recognition memory: there also, participants assume as default that an item is new (i.e., hasn't been presented in the study phase), unless they have evidence for that it is old.

We found no evidence for a metacognitive asymmetry between default-complying and default-violating signals. Furthermore, in Experiment 6 participants were *slower* and gave *lower* confidence ratings when they reported seeing a flipped letter: a significant finding that stood in direct contrast to the default-reasoning proposal. We interpreted our findings as placing the metacognitive asymmetry for detection judgments at lower levels of the cognitive hierarchy, potentially in early visual processing. 

A similar behavioural profile for the identification of default-complying and default violating stimuli does not stand in contrast to the proposal that inference about absence does involve a default-reasoning component, and that as a result it requires reliance on a mental self model (see Section \@ref(intro-2nd-order)). Nevertheless, finding a metacognitive asymmetry for expectation violations would have provided strong support for this framework, which we did not get from our findings.


## Future directions

As the above list makes clear, the investigation of the link between inference about absence and self-modeling is far from being complete. The data are telling us that there is more to the story than default reasoning and reliance on self knowledge, or that my particular formulation of these concepts is lacking. More work is needed to further investigate the mechanisms that allow humans to form explicit representation of absence based on the absence of evidence, and how this relates to their generative models of their own perception and cognition. In the following, I list two avenues for future studies: leveraging failures of a self-model, and using inference about absence in more naturalistic settings.

### Failures of a self-model {#failures}

The structure of models is best revealed when they fail to faithfully represent their object. For example, a failure of the body-schema to correctly identify the position of one's arm following synchronous touch [@botvinick1998rubber] has advanced our understanding of how humans represent their own bodies, and how they update these representations based on sensory evidence [@cowie2013children; @kammers2009rubber; @tsakiris2005rubber]. Systematic errors in participants' predictions of the physical effects of collisions informed theories of people's intuitive understanding of physics [@sanborn2013reconciling]. Lastly, children's failure to ascribe a false-belief to an agent provided cognitive scientists with an experimental handle on the development of a Theory of Mind between the ages of 2.5 and 4 [@gopnik1992child]. 

Similarly, a scientific investigation of the mental self model can make use of cases in which this model fails to accurately represent the mental self. In the introduction, I provided two examples for misrepresentations that were revealed by suboptimal inference about absence: in near-threshold detection, participants overestimate the effect of eccentricity on perceptual sensitivity [@odegaard2018inflation; @solovey2015decisional], and in visual search participants fail to fully represent the search advantage for unfamiliar targets [@wang1994familiarity; @zhang2020visual; but see Chapter \@ref(ch:MVS) for evidence that intuitive theories of visual search are sensitive to this advantage, at least to some extent]. Focusing on these mismatches between the mental self (including perception, attention, and higher cognition) and the mental self-model has the potential to uncover the boundaries of the self model, the simplifications it makes, and its computational building blocks.

For example, large-scale online data collection with adaptive [@he2020new; @cavagnaro2011model] and sequential designs [@sanborn2008markov; @hsu2019identifying; @langlois2021serial] now affords to identify stimulus features that affect visual search in target-present trials more than in target-absent trials or vice versa, indicating a mismatch between visual attention and participants' model of their own attention. Beside directly contributing to our knowledge of the contents and structure of the mental self model (e.g., the mental self model is better calibrated for basic visual features than for experience-based ones), this systematic mapping of model misrepresentations can then be used to ask how is the mental self model expanded and adjusted based on experience, by measuring how these biases change in light of task experience. Collecting data from multiple subjects on multiple test items has been successful in investigating factors that contribute to image memorability, to subjective memorability scores, and to mismatches between the two [@isola2013makes; @rust2020understanding].

### Inference about asbence in multi-dimensional and hierarchical representational spaces

in order to achieve high levels of experimental control, experiments in this thesis have mostly used simple stimuli: random dot kinematograms, visual gratings, flickering patches, and simple geometrical shapes. Using low-level visual stimuli has made is possible to precisely control the input to participants' perceptual system (e.g., in the form of signal to noise ratio). However, restricting our focus to the representation of presence and absence in low-dimensional representational spaces has potentially masked some crucial properties of inference about absence that are revealed in high-dimensional, hierarchically structured representational spaces (see Section \@ref(intro-2nd-order) in the introduction). 

Consider, for example, the results of the imaging experiment in Chapter \@ref(ch:fMRI), where to our surprise we found no univariate difference in activation between detection 'yes' and 'no' responses. One explanation is that our limited stimulus set (noise and right- and left-tilted gratings embedded in noise) has allowed subjects to form active representations of stimulus absence (in this case, noise), bypassing the need for counterfactual reasoning for inferring absence. In Chapter \@ref(ch:RC), Experiment 2, reverse correlation analysis revealed an active accumulation of evidence for absence (in the form of overall darkness).

In Future studies, using high-dimensional stimuli such as photographs of animals [@kellij2018foundations], faces, or words [@kay2017bottom] may render it impossible to accumulate evidence for absence, instead pushing participants to adopt a counterfacutal reasoning heuristic. Combinatorically, the number of all possible stimuli is exponential in the number of dimensions, making an exhaustive search impossible in high-dimensional stimulus spaces. In such highly asymmetric spaces, a counterfactual heuristic (would I have seen a target stimulus if it was present?) may be more advantageous.


## Conclusion

In this thesis, I investigated the role of self modeling in inference about absence. Using visual search and perceptual detection and discrimination, I asked what separates decisions about the presence of a signal from decisions about signal absence, and to what extent the difference between these two types of decisions is related to the reliance of the latter on counterfactual reasoning on the basis of a self-model. Overall, I observed mixed results for and against this proposal. In visual search, participants' rich and accurate explicit theory of their own visual search behaviour played no role in deciding that a target was absent from a display. In near-threshold detection, a parametric modulation of confidence on brain activation was similar for decisions about the presence and the absence of a stimulus, except for in the right temporoparietal junction - a brain region that has been associated with monitoring one's own attention, as well as the attention of other agents. Finally, discrimination tasks with stimuli that varied in the presence or absence of a local feature, a global feature, or a default violation, dissociated between factors that independently contribute to the behavioural differences between decisions about the presence and absence of a stimulus. Overall, my findings suggest that decisions about presence and absence differ in more than one way. Self-modeling and counterfactual thinking may account for some of these differences, but not for all of them. 