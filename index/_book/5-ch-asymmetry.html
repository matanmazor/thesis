<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Metacognitive asymmetries in visual perception | Self-Modelling in Inference about Absence</title>
  <meta name="description" content="Chapter 5 Metacognitive asymmetries in visual perception | Self-Modelling in Inference about Absence" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Metacognitive asymmetries in visual perception | Self-Modelling in Inference about Absence" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Metacognitive asymmetries in visual perception | Self-Modelling in Inference about Absence" />
  
  
  

<meta name="author" content="Matan Mazor" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4-ch-fMRI.html"/>
<link rel="next" href="general-discussion.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminary Content</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#impact-statement"><i class="fa fa-check"></i>Impact Statement</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="0.1" data-path="introduction.html"><a href="introduction.html#inference-about-absence"><i class="fa fa-check"></i><b>0.1</b> Inference about absence</a></li>
<li class="chapter" data-level="0.2" data-path="introduction.html"><a href="introduction.html#formalabsence"><i class="fa fa-check"></i><b>0.2</b> Probabilistic reasoning, criterion setting, and self knowledge</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#symmetrical-definition"><i class="fa fa-check"></i>Symmetrical definition:</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#dissymmetrical-definition"><i class="fa fa-check"></i>Dissymmetrical definition:</a></li>
<li class="chapter" data-level="0.2.1" data-path="introduction.html"><a href="introduction.html#intro-2nd-order"><i class="fa fa-check"></i><b>0.2.1</b> Second-order cognition</a></li>
<li class="chapter" data-level="0.2.2" data-path="introduction.html"><a href="introduction.html#detectionmodels"><i class="fa fa-check"></i><b>0.2.2</b> Computational models of detection</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#htm"><i class="fa fa-check"></i>The High-Threshold model</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#sdt"><i class="fa fa-check"></i>Signal Detection Theory</a></li>
</ul></li>
<li class="chapter" data-level="0.3" data-path="introduction.html"><a href="introduction.html#detection-i-would-have-noticed-it"><i class="fa fa-check"></i><b>0.3</b> Detection: “I would have noticed it”</a></li>
<li class="chapter" data-level="0.4" data-path="introduction.html"><a href="introduction.html#intro:search"><i class="fa fa-check"></i><b>0.4</b> Visual search: “I would have found it”</a></li>
<li class="chapter" data-level="0.5" data-path="introduction.html"><a href="introduction.html#memory-i-would-have-remembered-it"><i class="fa fa-check"></i><b>0.5</b> Memory: “I would have remembered it”</a></li>
<li class="chapter" data-level="0.6" data-path="introduction.html"><a href="introduction.html#the-development-of-a-self-model"><i class="fa fa-check"></i><b>0.6</b> The development of a self-model</a></li>
<li class="chapter" data-level="0.7" data-path="introduction.html"><a href="introduction.html#this-thesis"><i class="fa fa-check"></i><b>0.7</b> This thesis</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-ch-termination.html"><a href="1-ch-termination.html"><i class="fa fa-check"></i><b>1</b> Efficient search termination without task experience: the role of second-order knowledge about visual search</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1-ch-termination.html"><a href="1-ch-termination.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="1-ch-termination.html"><a href="1-ch-termination.html#experiment-1"><i class="fa fa-check"></i><b>1.2</b> Experiment 1</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1-ch-termination.html"><a href="1-ch-termination.html#participants"><i class="fa fa-check"></i><b>1.2.1</b> Participants</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-ch-termination.html"><a href="1-ch-termination.html#procedure"><i class="fa fa-check"></i><b>1.2.2</b> Procedure</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-ch-termination.html"><a href="1-ch-termination.html#randomization"><i class="fa fa-check"></i><b>1.2.3</b> Randomization</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-ch-termination.html"><a href="1-ch-termination.html#data-analysis"><i class="fa fa-check"></i><b>1.2.4</b> Data analysis</a></li>
<li class="chapter" data-level="1.2.5" data-path="1-ch-termination.html"><a href="1-ch-termination.html#results"><i class="fa fa-check"></i><b>1.2.5</b> Results</a></li>
<li class="chapter" data-level="1.2.6" data-path="1-ch-termination.html"><a href="1-ch-termination.html#additional-analysis-first-trial-only"><i class="fa fa-check"></i><b>1.2.6</b> Additional analysis: first trial only</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-ch-termination.html"><a href="1-ch-termination.html#experiment-2"><i class="fa fa-check"></i><b>1.3</b> Experiment 2</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1-ch-termination.html"><a href="1-ch-termination.html#participants-1"><i class="fa fa-check"></i><b>1.3.1</b> Participants</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-ch-termination.html"><a href="1-ch-termination.html#procedure-1"><i class="fa fa-check"></i><b>1.3.2</b> Procedure</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-ch-termination.html"><a href="1-ch-termination.html#results-1"><i class="fa fa-check"></i><b>1.3.3</b> Results</a></li>
<li class="chapter" data-level="1.3.4" data-path="1-ch-termination.html"><a href="1-ch-termination.html#additional-analyses"><i class="fa fa-check"></i><b>1.3.4</b> Additional Analyses</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-ch-termination.html"><a href="1-ch-termination.html#discussion"><i class="fa fa-check"></i><b>1.4</b> Discussion</a></li>
<li class="chapter" data-level="1.5" data-path="1-ch-termination.html"><a href="1-ch-termination.html#conclusion"><i class="fa fa-check"></i><b>1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html"><i class="fa fa-check"></i><b>2</b> Internal models of visual search are rich, person-specific, and mostly accurate</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#introduction-2"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#experiments-1-and-2-shape-orientation-and-color"><i class="fa fa-check"></i><b>2.2</b> Experiments 1 and 2: shape, orientation, and color</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#participants-2"><i class="fa fa-check"></i><b>2.2.1</b> Participants</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#procedure-2"><i class="fa fa-check"></i><b>2.2.2</b> Procedure</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#results-2"><i class="fa fa-check"></i><b>2.2.3</b> Results</a></li>
<li class="chapter" data-level="" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#estimation-accuracy"><i class="fa fa-check"></i>Estimation accuracy</a></li>
<li class="chapter" data-level="" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#a-graded-representation-of-search-efficiency"><i class="fa fa-check"></i>A graded representation of search efficiency</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#experiments-3-and-4-complex-unfamiliar-stimuli"><i class="fa fa-check"></i><b>2.3</b> Experiments 3 and 4: complex, unfamiliar stimuli</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#participants-3"><i class="fa fa-check"></i><b>2.3.1</b> Participants</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#procedure-3"><i class="fa fa-check"></i><b>2.3.2</b> Procedure</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#results-3"><i class="fa fa-check"></i><b>2.3.3</b> Results</a></li>
<li class="chapter" data-level="" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#estimation-time"><i class="fa fa-check"></i>Estimation time</a></li>
<li class="chapter" data-level="" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#asymmetry"><i class="fa fa-check"></i>Visual search asymmetry</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-ch-MVS.html"><a href="2-ch-MVS.html#discussion-1"><i class="fa fa-check"></i><b>2.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-ch-RC.html"><a href="3-ch-RC.html"><i class="fa fa-check"></i><b>3</b> Evidence weightings in confidence judgments for detection and discrimination</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3-ch-RC.html"><a href="3-ch-RC.html#introduction-3"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3-ch-RC.html"><a href="3-ch-RC.html#experiment-1-1"><i class="fa fa-check"></i><b>3.2</b> Experiment 1</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3-ch-RC.html"><a href="3-ch-RC.html#methods"><i class="fa fa-check"></i><b>3.2.1</b> Methods</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-ch-RC.html"><a href="3-ch-RC.html#randomization-1"><i class="fa fa-check"></i><b>3.2.2</b> Randomization</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-ch-RC.html"><a href="3-ch-RC.html#analysis"><i class="fa fa-check"></i><b>3.2.3</b> Analysis</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-ch-RC.html"><a href="3-ch-RC.html#results-4"><i class="fa fa-check"></i><b>3.2.4</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-ch-RC.html"><a href="3-ch-RC.html#experiment-2-1"><i class="fa fa-check"></i><b>3.3</b> Experiment 2</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-ch-RC.html"><a href="3-ch-RC.html#methods-1"><i class="fa fa-check"></i><b>3.3.1</b> Methods</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-ch-RC.html"><a href="3-ch-RC.html#randomization-2"><i class="fa fa-check"></i><b>3.3.2</b> Randomization</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-ch-RC.html"><a href="3-ch-RC.html#results-5"><i class="fa fa-check"></i><b>3.3.3</b> Results</a></li>
<li class="chapter" data-level="3.3.4" data-path="3-ch-RC.html"><a href="3-ch-RC.html#detection-signal-trials-1"><i class="fa fa-check"></i><b>3.3.4</b> Detection signal trials</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-ch-RC.html"><a href="3-ch-RC.html#experiment-3"><i class="fa fa-check"></i><b>3.4</b> Experiment 3</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3-ch-RC.html"><a href="3-ch-RC.html#methods-2"><i class="fa fa-check"></i><b>3.4.1</b> Methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-ch-RC.html"><a href="3-ch-RC.html#results-6"><i class="fa fa-check"></i><b>3.4.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-ch-RC.html"><a href="3-ch-RC.html#discussion-2"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html"><i class="fa fa-check"></i><b>4</b> Distinct neural contributions to metacognition for detecting (but not discriminating) visual stimuli</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#introduction-4"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#methods-and-materials"><i class="fa fa-check"></i><b>4.2</b> Methods and Materials</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#participants-7"><i class="fa fa-check"></i><b>4.2.1</b> Participants</a></li>
<li class="chapter" data-level="4.2.2" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#design-and-procedure"><i class="fa fa-check"></i><b>4.2.2</b> Design and procedure</a></li>
<li class="chapter" data-level="4.2.3" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#scanning-parameters"><i class="fa fa-check"></i><b>4.2.3</b> Scanning parameters</a></li>
<li class="chapter" data-level="4.2.4" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#analysis-1"><i class="fa fa-check"></i><b>4.2.4</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#results-7"><i class="fa fa-check"></i><b>4.3</b> Results</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#behavioural-results"><i class="fa fa-check"></i><b>4.3.1</b> Behavioural results</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#imaging-results"><i class="fa fa-check"></i><b>4.3.2</b> Imaging results</a></li>
<li class="chapter" data-level="4.3.3" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#computational-models"><i class="fa fa-check"></i><b>4.3.3</b> Computational models</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-ch-fMRI.html"><a href="4-ch-fMRI.html#discussion-3"><i class="fa fa-check"></i><b>4.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html"><i class="fa fa-check"></i><b>5</b> Metacognitive asymmetries in visual perception</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#introduction-5"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#methods-3"><i class="fa fa-check"></i><b>5.2</b> Methods</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#participants-8"><i class="fa fa-check"></i><b>5.2.1</b> Participants</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#procedure-4"><i class="fa fa-check"></i><b>5.2.2</b> Procedure</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#data-analysis-1"><i class="fa fa-check"></i><b>5.2.3</b> Data analysis</a></li>
<li class="chapter" data-level="5.2.4" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#analysis-plan"><i class="fa fa-check"></i><b>5.2.4</b> Dependent variables and analysis plan</a></li>
<li class="chapter" data-level="5.2.5" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#statistical-power"><i class="fa fa-check"></i><b>5.2.5</b> Statistical power</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#data-availability"><i class="fa fa-check"></i><b>5.3</b> Data availability</a></li>
<li class="chapter" data-level="5.4" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#code-availability"><i class="fa fa-check"></i><b>5.4</b> Code availability</a></li>
<li class="chapter" data-level="5.5" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#deviations"><i class="fa fa-check"></i><b>5.5</b> Deviations from pre-registration</a></li>
<li class="chapter" data-level="5.6" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#results-8"><i class="fa fa-check"></i><b>5.6</b> Results</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#experiment-1-q-vs.-o"><i class="fa fa-check"></i><b>5.6.1</b> Experiment 1: <em>Q</em> vs. <em>O</em></a></li>
<li class="chapter" data-level="5.6.2" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#experiment-2-c-vs.-o"><i class="fa fa-check"></i><b>5.6.2</b> Experiment 2: C vs. O</a></li>
<li class="chapter" data-level="5.6.3" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#experiment-3-tilted-vs.-vertical-lines"><i class="fa fa-check"></i><b>5.6.3</b> Experiment 3: tilted vs. vertical lines</a></li>
<li class="chapter" data-level="5.6.4" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#experiment-4-curved-vs.-straight-lines"><i class="fa fa-check"></i><b>5.6.4</b> Experiment 4: curved vs. straight lines</a></li>
<li class="chapter" data-level="5.6.5" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#experiment-5-upward-tilted-vs.-downward-tilted-cubes"><i class="fa fa-check"></i><b>5.6.5</b> Experiment 5: upward-tilted vs. downward-tilted cubes</a></li>
<li class="chapter" data-level="5.6.6" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#experiment-6-flipped-vs.-normal-letters"><i class="fa fa-check"></i><b>5.6.6</b> Experiment 6: flipped vs. normal letters</a></li>
<li class="chapter" data-level="5.6.7" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#asymmetry-summary"><i class="fa fa-check"></i><b>5.6.7</b> Experiments 1-6: summary</a></li>
<li class="chapter" data-level="5.6.8" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#experiment-7-exploratory-grating-vs.-noise"><i class="fa fa-check"></i><b>5.6.8</b> Experiment 7 (exploratory): grating vs. noise</a></li>
<li class="chapter" data-level="5.6.9" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#exploratory-analysis"><i class="fa fa-check"></i><b>5.6.9</b> Exploratory analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#discussion-4"><i class="fa fa-check"></i><b>5.7</b> Discussion</a></li>
<li class="chapter" data-level="5.8" data-path="5-ch-asymmetry.html"><a href="5-ch-asymmetry.html#conclusion-1"><i class="fa fa-check"></i><b>5.8</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html"><i class="fa fa-check"></i>General Discussion</a>
<ul>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#didnotfind"><i class="fa fa-check"></i>What I didn’t find</a>
<ul>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#chapter-1-no-correlation-with-explicit-metacognition"><i class="fa fa-check"></i>Chapter 1: no correlation with explicit metacognition</a></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#chapter-3-no-effect-of-confidence-in-signal-presence"><i class="fa fa-check"></i>Chapter 3: no effect of confidence in signal presence</a></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#chapter-4-only-minor-differences-in-brain-activity-between-inference-about-absence-and-presence"><i class="fa fa-check"></i>Chapter 4: only minor differences in brain activity between inference about absence and presence</a></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#chapter-5-no-metacognitive-asymmetry-between-default-complying-and-default-violating-signals"><i class="fa fa-check"></i>Chapter 5: no metacognitive asymmetry between default-complying and default-violating signals</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#withoutselfmodel"><i class="fa fa-check"></i>Inference about absence without self-modelling</a>
<ul>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#patch"><i class="fa fa-check"></i>Patch-leaving in foraging</a></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#absenceperception"><i class="fa fa-check"></i>Direct perception</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#future-directions"><i class="fa fa-check"></i>Future directions</a>
<ul>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#failures"><i class="fa fa-check"></i>Failures of a self-model</a></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#inference-about-asbence-in-multi-dimensional-and-hierarchical-representational-spaces"><i class="fa fa-check"></i>Inference about asbence in multi-dimensional and hierarchical representational spaces</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html#conclusion-2"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html"><i class="fa fa-check"></i><b>A</b> Signal Detection Theory</a>
<ul>
<li class="chapter" data-level="A.1" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html#app1-ROC"><i class="fa fa-check"></i><b>A.1</b> ROC and zROC curves</a></li>
<li class="chapter" data-level="A.2" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html#app1-uvSDT"><i class="fa fa-check"></i><b>A.2</b> Unequal-variance (uv) SDT</a></li>
<li class="chapter" data-level="A.3" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html#app1-mc"><i class="fa fa-check"></i><b>A.3</b> SDT Measures for Metacognition</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-app1-RT.html"><a href="B-app1-RT.html"><i class="fa fa-check"></i><b>B</b> Supp. materials for ch. 1</a>
<ul>
<li class="chapter" data-level="B.1" data-path="B-app1-RT.html"><a href="B-app1-RT.html#effect-of-rt-based-trial-exclusion"><i class="fa fa-check"></i><b>B.1</b> Effect of RT-based trial exclusion</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="B-app1-RT.html"><a href="B-app1-RT.html#experiment-1-2"><i class="fa fa-check"></i><b>B.1.1</b> Experiment 1</a></li>
<li class="chapter" data-level="B.1.2" data-path="B-app1-RT.html"><a href="B-app1-RT.html#experiment-2-2"><i class="fa fa-check"></i><b>B.1.2</b> Experiment 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-supp.-materials-for-ch.-2.html"><a href="C-supp.-materials-for-ch.-2.html"><i class="fa fa-check"></i><b>C</b> Supp. materials for ch. 2</a>
<ul>
<li class="chapter" data-level="C.1" data-path="C-supp.-materials-for-ch.-2.html"><a href="C-supp.-materials-for-ch.-2.html#app2-bonus"><i class="fa fa-check"></i><b>C.1</b> Bonus structure</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html"><i class="fa fa-check"></i><b>D</b> Supp. materials for ch. 3</a>
<ul>
<li class="chapter" data-level="D.1" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#additional-analyses-exp.-1"><i class="fa fa-check"></i><b>D.1</b> Additional analyses: Exp. 1</a>
<ul>
<li class="chapter" data-level="D.1.1" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#appRC-asymmetries1"><i class="fa fa-check"></i><b>D.1.1</b> Response time, confidence, and metacognitive sensitivity differences</a></li>
<li class="chapter" data-level="D.1.2" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#zroc-curves"><i class="fa fa-check"></i><b>D.1.2</b> zROC curves</a></li>
<li class="chapter" data-level="D.1.3" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#confidence-response-time-alignment"><i class="fa fa-check"></i><b>D.1.3</b> Confidence response-time alignment</a></li>
<li class="chapter" data-level="D.1.4" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#global-metacognitive-estimates"><i class="fa fa-check"></i><b>D.1.4</b> Global metacognitive estimates</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#additional-analyses-exp.-2"><i class="fa fa-check"></i><b>D.2</b> Additional analyses: Exp. 2</a>
<ul>
<li class="chapter" data-level="D.2.1" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#appRC-asymmetries2"><i class="fa fa-check"></i><b>D.2.1</b> Response time, confidence, and metacognitive sensitivity differences</a></li>
<li class="chapter" data-level="D.2.2" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#zroc-curves-1"><i class="fa fa-check"></i><b>D.2.2</b> zROC curves</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#additional-analyses-exp.-3"><i class="fa fa-check"></i><b>D.3</b> Additional analyses: Exp. 3</a>
<ul>
<li class="chapter" data-level="D.3.1" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#appRC-asymmetries3"><i class="fa fa-check"></i><b>D.3.1</b> Response time, confidence, and metacognitive sensitivity differences</a></li>
<li class="chapter" data-level="D.3.2" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#appRC-standardonly"><i class="fa fa-check"></i><b>D.3.2</b> Reverse correlation analysis of standard trials only</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#appRC-PDRC"><i class="fa fa-check"></i><b>D.4</b> Pseudo-discrimination analysis</a>
<ul>
<li class="chapter" data-level="D.4.1" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#exp.-1"><i class="fa fa-check"></i><b>D.4.1</b> Exp. 1</a></li>
<li class="chapter" data-level="D.4.2" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#exp.-2"><i class="fa fa-check"></i><b>D.4.2</b> Exp. 2</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#app2-simulation"><i class="fa fa-check"></i><b>D.5</b> Stimulus-dependent noise model</a>
<ul>
<li class="chapter" data-level="D.5.1" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#discrimination"><i class="fa fa-check"></i><b>D.5.1</b> Discrimination</a></li>
<li class="chapter" data-level="D.5.2" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#detection-2"><i class="fa fa-check"></i><b>D.5.2</b> Detection</a></li>
<li class="chapter" data-level="D.5.3" data-path="D-appRC-everything.html"><a href="D-appRC-everything.html#effects-of-evidence-on-decision-and-confidence-exp.-2-and-3"><i class="fa fa-check"></i><b>D.5.3</b> Effects of evidence on decision and confidence: Exp. 2 and 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html"><i class="fa fa-check"></i><b>E</b> Supp. materials for ch. 4</a>
<ul>
<li class="chapter" data-level="E.1" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-buttonpresses"><i class="fa fa-check"></i><b>E.1</b> Confidence button presses</a></li>
<li class="chapter" data-level="E.2" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-zROC"><i class="fa fa-check"></i><b>E.2</b> zROC curves</a></li>
<li class="chapter" data-level="E.3" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-GC-DM"><i class="fa fa-check"></i><b>E.3</b> Global confidence design matrix</a></li>
<li class="chapter" data-level="E.4" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-ROIconf"><i class="fa fa-check"></i><b>E.4</b> Effect of confidence in our pre-specified ROIs</a></li>
<li class="chapter" data-level="E.5" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-varianceRat"><i class="fa fa-check"></i><b>E.5</b> SDT variance ratio correlation with the quadratic confidence effect</a></li>
<li class="chapter" data-level="E.6" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-efficiency"><i class="fa fa-check"></i><b>E.6</b> Correlation of metacognitive efficiency with linear and quadratic confidence effects</a></li>
<li class="chapter" data-level="E.7" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-cross"><i class="fa fa-check"></i><b>E.7</b> Confidence-decision cross classification</a></li>
<li class="chapter" data-level="E.8" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-SDT"><i class="fa fa-check"></i><b>E.8</b> Static Signal Detection Theory</a>
<ul>
<li class="chapter" data-level="E.8.1" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#discrimination-1"><i class="fa fa-check"></i><b>E.8.1</b> Discrimination</a></li>
<li class="chapter" data-level="E.8.2" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#detection-3"><i class="fa fa-check"></i><b>E.8.2</b> Detection</a></li>
</ul></li>
<li class="chapter" data-level="E.9" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3:Dynamic"><i class="fa fa-check"></i><b>E.9</b> Dynamic Criterion</a>
<ul>
<li class="chapter" data-level="E.9.1" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#discrimination-2"><i class="fa fa-check"></i><b>E.9.1</b> Discrimination</a></li>
<li class="chapter" data-level="E.9.2" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#detection-4"><i class="fa fa-check"></i><b>E.9.2</b> Detection</a></li>
</ul></li>
<li class="chapter" data-level="E.10" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#app3-Monitoring"><i class="fa fa-check"></i><b>E.10</b> Attention Monitoring</a>
<ul>
<li class="chapter" data-level="E.10.1" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#discrimination-3"><i class="fa fa-check"></i><b>E.10.1</b> Discrimination</a></li>
<li class="chapter" data-level="E.10.2" data-path="E-supp.-materials-for-ch.-4.html"><a href="E-supp.-materials-for-ch.-4.html#detection-5"><i class="fa fa-check"></i><b>E.10.2</b> Detection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="F" data-path="F-supp.-materials-for-ch.-5.html"><a href="F-supp.-materials-for-ch.-5.html"><i class="fa fa-check"></i><b>F</b> Supp. materials for ch. 5</a>
<ul>
<li class="chapter" data-level="F.1" data-path="F-supp.-materials-for-ch.-5.html"><a href="F-supp.-materials-for-ch.-5.html#robustness-region"><i class="fa fa-check"></i><b>F.1</b> Robustness Region</a></li>
</ul></li>
<li class="chapter" data-level="G" data-path="G-reproducibility-receipt.html"><a href="G-reproducibility-receipt.html"><i class="fa fa-check"></i><b>G</b> Reproducibility receipt</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Modelling in Inference about Absence</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-asymmetry" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Metacognitive asymmetries in visual perception</h1>
<div id="matan-mazor-rani-moran-stephen-m.-fleming" class="section level4 unnumbered">
<h4>Matan Mazor, Rani Moran &amp; Stephen M. Fleming</h4>
<p>In previous chapters we examined inference about absence and its relation to self-modelling, focusing on the absence of entire shapes (Chapter <a href="1-ch-termination.html#ch-termination">1</a>), visual gratings (Chapter <a href="4-ch-fMRI.html#ch-fMRI">4</a>) and non-random patterns in otherwise random displays (Chapter <a href="3-ch-RC.html#ch-RC">3</a>). In all cases we find that decisions about absence are slower than decisions about presence, and in chapters <a href="3-ch-RC.html#ch-RC">3</a> and <a href="4-ch-fMRI.html#ch-fMRI">4</a> we further replicate findings of higher levels of confidence and improved metacognitive sensitivity for decisions about the presence compared to the absence of objects. in this last chapter, based on a Registered Report, I ask how far can we stretch the definition of ‘absence,’ focusing on the absence of stimulus features or expectation violations, rather than entire objects or stimuli. Our pre-registered prediction was that differences in the processing of presence and absence reflect a default mode of reasoning: assuming absence unless evidence is available for presence. In a Registered Report, we predicted asymmetries in response time, confidence, and metacognitive sensitivity in discriminating between stimulus categories that vary in the presence or absence of a distinguishing feature, or in their compliance with an expected default state. Six experiments, using six pairs of stimuli, provide evidence that like the presence of entire shapes or gratings, the presence of local and global stimulus features gives rise to faster, more confident responses. Contrary to our hypothesis, however, the presence or absence of a local feature has no effect on metacognitive sensitivity. Our results weigh against our proposal of a link between the detection metacognitive asymmetry and default reasoning, and are instead consistent with a low-level visual origin of the metacognitive asymmetry between detection ‘yes’ and ‘no’ responses.</p>
</div>
<div id="introduction-5" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<p>At any given moment, there are many more things that are not there than things that are there. As a result, and in order to efficiently represent the environment, perceptual and cognitive systems have evolved to represent presences, and absence is implicitly represented as a default state <span class="citation">(Oaksford, 2002; Oaksford &amp; Chater, 2001)</span>. One corollary of this is that presence can be inferred from bottom-up sensory signals, but absence is never explicitly represented in sensory channels and must instead by inferred based on top-down expectations about the likelihood of detecting a hypothetical signal, had it been present. Experiments on human subjects accordingly suggest that representing absence is more cognitively demanding than representing presence, even in simple perceptual tasks, as is evident in slower reactions to stimulus absence than stimulus presence in near-threshold visual detection <span class="citation">(Mazor, Friston, &amp; Fleming, 2020)</span>, in a general difficulty to form associations with absence <span class="citation">(Newman, Wolff, &amp; Hearst, 1980)</span>, and in the late acquisition of explicit representations of absence in development <span class="citation">(Coldren &amp; Haaf, 2000; e.g., Sainsbury, 1971; for a review on the representation of nothing see Hearst, 1991)</span>.</p>
<p>An overarching difficulty in representing absence may reflect the metacognitive nature of absence representations; to represent something as absent, one must assume that they would have detected it had it been present. In philosophical writings, this form of higher-order, metacognitive inference-about-absence is known as <em>argument from epistemic closure</em>, or <em>argument from self-knowledge</em> [<em>If it was true, I would have known it</em>; <span class="citation">Walton (1992)</span>; <span class="citation">De Cornulier (1988)</span>]. Strikingly, quantitative measures of metacognitive insight are consistently found to be lower for decisions about absence than for decisions about presence. When asked to rate their subjective confidence following near-threshold detection decisions, subjective confidence ratings following ‘target absent’ judgments are commonly lower, and less aligned with objective accuracy, than following ‘target present’ judgments [Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-asymmetry">5.1</a>; <span class="citation">Kanai, Walsh, &amp; Tseng (2010)</span>; <span class="citation">Meuwese, Loon, Lamme, &amp; Fahrenfort (2014)</span>; <span class="citation">Kellij, Fahrenfort, Lau, Peters, &amp; Odegaard (2018)</span>; <span class="citation">Mazor, Friston, &amp; Fleming (2020)</span>].</p>
<p>Metacognitive asymmetries have not only been observed for judgments about the presence or absence of whole physical objects and stimuli, but also for the presence or absence of cognitive variables such as memory traces. For instance, in recognition memory, subjects typically show poor metacognitive sensitivity for judgments about the absence of memories [such as when judging that they haven’t seen a study item before; <span class="citation">Higham, Perfect, &amp; Bruno (2009)</span>]. Unlike the absence of a visual stimulus, the absence of a memory is not localized in space and does not correspond with a specific representation of ‘nothing.’</p>
<p>One way of conceptualizing these findings is that absence asymmetries emerge as a function of default reasoning - absences are considered the ‘default,’ and information about perceptual or mnemonic presence is accumulated and tested against this default. For instance, an asymmetry may emerge in recognition memory because the presence of memories is actively represented, and the absence of memories is assumed as the default unless evidence is available for the contrary. In the same way, other visual features that are not typically treated as presences or absences may still be coded relative to a default, assuming one state unless evidence is available for the contrary (e.g., assuming that a cookie is sweet rather than salty). However, whether a metacognitive asymmetry in processing presence and absence generalizes to these more abstract violations of default expectations remains unknown. Here we set out to map out the structure of absence representations by testing for metacognitive asymmetries in the presence and absence of attributes at different levels of representation - from concrete objects, to visual features, to violations of default expectations.</p>
<p>Our choice of stimuli draws inspiration from visual search - a field where asymmetries are observed for a variety of stimulus types and features. In visual search, participants typically take longer to search for a target that is marked by the absence of a distinguishing feature, as compared to searching for a target that is marked by the presence of a feature relative to distractors <span class="citation">(A. Treisman &amp; Gormican, 1988; A. Treisman &amp; Souther, 1985)</span>. Interestingly, <em>search asymmetries</em> have been demonstrated not only for the absence or presence of concrete physical features, but also for the presence or absence of deviations from a more abstract default state, which can be based on experience, culture, and contextual expectations [see methods; <span class="citation">Von Grünau &amp; Dubé (1994)</span>; <span class="citation">U. Frith (1974)</span>; <span class="citation">Wang, Cavanagh, &amp; Green (1994)</span>; <span class="citation">Gandolfo &amp; Downing (2020)</span>].</p>
<p>Of special interest for our study are these latter asymmetries due to expectation violations, and their relation with asymmetries induced by the presence or absence of local and global features. Observing a metacognitive asymmetry for expectation violations as well as for the presence and absence of object features would support a strong link between the representation of absence and default reasoning, where differences in metacognitive sensitivity reflect differences in the processing of information that agrees or contrasts with the expected default state.</p>
<p>While traditional accounts interpreted visual search asymmetries as reflecting a qualitative advantage for the cognitive representation of presence [affording a parallel search in the case of feature-present search only; <span class="citation">A. Treisman &amp; Gormican (1988)</span>], other models attribute the asymmetry to differences in the distributions of perceptual signals already at the sensory level <span class="citation">(Dosher, Han, &amp; Lu, 2004; Vincent, 2011)</span>. Similarly, in the case of metacognitive asymmetries, the idea that decisions about absence are qualitatively different from decisions about presence has been challenged by an excellent fit of simple models that assume unequal variance for the signal-present and signal-absent sensory distributions, a model that does not assume any qualitative difference between the two decisions <span class="citation">(Kellij, Fahrenfort, Lau, Peters, &amp; Odegaard, 2018)</span>. Deciding between these model families is beyond the scope of this project. However, identifying metacognitive asymmetries for abstract cognitive variables such as familiarity could help refine these models, for instance by revealing that representing deviations from a default state is an overarching principle of cognitive organization, one that goes beyond specific features of visual perception.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:asymmetry-asymmetry"></span>
<img src="figure/asymmetry/asymmetry.png" alt="In visual detection, subjective confidence ratings following judgments about target absence are typically lower, and less correlated with objective accuracy than following judgments about target presence. Top panel: a typical detection experiment. The participant reports whether a visual grating was present or absent, and then rates their subjective decision confidence. Bottom left: typically, mean confidence in 'yes' responses (blue) is higher than in 'no' responses (red). This effect is much more pronounced in correct trials. Bottom right: the interaction between accuracy and response type on confidence (metacognitive asymmetry) manifests as a lower area under the response conditional type 2 ROC curve (AUROC2) for 'no' responses compared with 'yes' responses. Plots do not directly correspond to a specific dataset, but portray typical results in visual detection." width="60%" />
<p class="caption">
Figure 5.1: In visual detection, subjective confidence ratings following judgments about target absence are typically lower, and less correlated with objective accuracy than following judgments about target presence. Top panel: a typical detection experiment. The participant reports whether a visual grating was present or absent, and then rates their subjective decision confidence. Bottom left: typically, mean confidence in ‘yes’ responses (blue) is higher than in ‘no’ responses (red). This effect is much more pronounced in correct trials. Bottom right: the interaction between accuracy and response type on confidence (metacognitive asymmetry) manifests as a lower area under the response conditional type 2 ROC curve (AUROC2) for ‘no’ responses compared with ‘yes’ responses. Plots do not directly correspond to a specific dataset, but portray typical results in visual detection.
</p>
</div>
</div>
<div id="methods-3" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Methods</h2>
<p>We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) --> The full registered protocol is available at <a href="osf.io/ed8n7">osf.io/ed8n7</a>.</p>
<p>We ran six experiments, that were identical except for the identity of the two stimuli <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> (and of the stimulus used for backward masking; see section <a href="5-ch-asymmetry.html#deviations">5.5</a> for details). Our choice of stimuli for this study was based on the visual search literature. For some stimulus pairs <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, searching for one <span class="math inline">\(S_1\)</span> among multiple <span class="math inline">\(S_2\)</span>s is more efficient than searching for one <span class="math inline">\(S_2\)</span> among multiple <span class="math inline">\(S_1\)</span>s. Such <em>search asymmetries</em> have been reported for stimulus pairs that are identical except for the presence and absence of a distinguishing feature. Importantly, distinguishing features vary in their level of abstraction, from concrete <em>local features</em> [finding a Q among Os is easier than the inverse search; <span class="citation">A. Treisman &amp; Souther (1985)</span>], through <em>global features</em> [finding a curved line among straight lines is easier than the inverse search; <span class="citation">A. Treisman &amp; Gormican (1988)</span>], and up to the presence or absence of abstract <em>expectation violations</em> [searching for an upward-tilted cube among downward-tilted cubes is easier than the inverse search, in line with a general expectation to see objects on the ground rather than floating in space; <span class="citation">Von Grünau &amp; Dubé (1994)</span>]. We treat these three types of asymmetries as reflecting a default-reasoning mode of representation, where the absence of features and/or the adherence of objects to prior expectations is tentatively accepted as a default by the visual system, unless evidence is available for the contrary <span class="citation">(A. Treisman &amp; Gormican, 1988; A. Treisman &amp; Souther, 1985)</span>. In this study, we test for metacognitive asymmetries for two stimulus features in each category, in six separate experiments with different participants (Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-trialstructure">5.2</a>). For each of the following stimulus pairs, searching for <span class="math inline">\(S_1\)</span> among multiple instances of <span class="math inline">\(S_2\)</span> has been found to be more efficient than the inverse search:</p>
<ol style="list-style-type: decimal">
<li><strong>Local feature: Addition of a stimulus part</strong>. <em>Q</em> and <em>O</em> were used as <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, respectively <span class="citation">(A. Treisman &amp; Souther, 1985)</span>.</li>
<li><strong>Local feature: Open ends</strong>. <em>C</em> and <em>O</em> were used as <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, respectively <span class="citation">(Takeda &amp; Yagi, 2000; A. Treisman &amp; Gormican, 1988; A. Treisman &amp; Souther, 1985)</span>.</li>
<li><strong>Global feature: Orientation</strong>. Tilted and vertical lines were used <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, respectively <span class="citation">(A. Treisman &amp; Gormican, 1988)</span>.</li>
<li><strong>Global feature: Curvature</strong>. Curved and straight lines were used as <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, respectively <span class="citation">(A. Treisman &amp; Gormican, 1988)</span>.</li>
<li><strong>Expectation violation: Viewing angle</strong>. Upward and Downward tilted cubes were used as <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, respectively <span class="citation">(Von Grünau &amp; Dubé, 1994)</span>.</li>
<li><strong>Expectation violation: Letter inversion</strong>. Flipped and normal <em>N</em> were used as <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, respectively <span class="citation">(U. Frith, 1974; Wang, Cavanagh, &amp; Green, 1994)</span>.</li>
</ol>
<p>The experiments quantified participants’ metacognitive sensitivity for discrimination judgments between <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>.</p>
<div id="participants-8" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Participants</h3>
<p>The research complied with all relevant ethical regulations, and was approved by the Research Ethics Committee of University College London (study ID number 1260/003). Participants were recruited via Prolific, and gave informed consent prior to their participation. They were selected based on their acceptance rate (&gt;95%) and for being native English speakers. For each of the six experiments, we aimed to collected data until we reached 106 included participants (after applying our pre-registered exclusion criteria). The entire experiment took 10-15 minutes to complete. Participants were paid between £1.25 to £2 for their participation, maintaining a median hourly wage of £6 or higher.</p>
</div>
<div id="procedure-4" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Procedure</h3>
<p>Experiments were programmed using the jsPsych and P5 JavaScript packages <span class="citation">(De Leeuw, 2015; McCarthy, 2015)</span>, and were hosted on a JATOS server <span class="citation">(Lange, Kuhn, &amp; Filevich, 2015)</span>.</p>
<p>After instructions, a practice phase, and a multiple-choice comprehension check, the main part of the experiment started. It comprised 96 trials separated into 6 blocks. Only the last 5 blocks were analyzed.</p>
<p>On each trial, participants made discrimination judgments on masked stimuli, and rated their subjective decision confidence on a continuous scale. After a fixation cross (500 ms), the target stimulus (<span class="math inline">\(S_1\)</span> or <span class="math inline">\(S_2\)</span>) was presented in the center of the screen for 50 ms, followed by a mask (100 ms). Stimulus onset asynchrony (SOA) was calibrated online in a 1-up-2-down procedure <span class="citation">(Levitt, 1971)</span>, with a multiplicative step factor of 0.9, and starting at 30 milliseconds. Participants then used their keyboard to make a discrimination judgment. Stimulus-key mapping was counterbalanced between participants. Following response, subjective confidence ratings were given on an analog scale by controlling the size of a colored circle with the computer mouse. High confidence was mapped to a big, blue circle, and low confidence to a small, red circle. We chose a continuous (rather than a more typical discrete) confidence scale in order to ensure sufficient variation in confidence ratings within the dynamic range of individual participants. This variation is useful for the extraction of the area under response conditional type 2 ROC curves (AUROC2). The confidence rating phase terminated once participants clicked their mouse, but not before 2000 ms. No trial-specific feedback was delivered about accuracy. In order to keep participants motivated and engaged, block-wise feedback was delivered between experimental blocks about overall accuracy, mean confidence in correct responses, and mean confidence in incorrect responses. Online demos the experiments can be accessed at <a href="matanmazor.github.io/asymmetry">matanmazor.github.io/asymmetry</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:asymmetry-trialstructure"></span>
<img src="figure/asymmetry/trial_structure.png" alt="Experiment design. Metacognitive asymmetry effects were tested for six stimulus features in six separate experiments, encompassing three levels of abstraction: local features, global features, and expectation violations. The presented trial corresponds to the first stimulus pair, with Q and O as stimuli." width="100%" />
<p class="caption">
Figure 5.2: Experiment design. Metacognitive asymmetry effects were tested for six stimulus features in six separate experiments, encompassing three levels of abstraction: local features, global features, and expectation violations. The presented trial corresponds to the first stimulus pair, with <em>Q</em> and <em>O</em> as stimuli.
</p>
</div>
<div id="randomization-3" class="section level4" number="5.2.2.1">
<h4><span class="header-section-number">5.2.2.1</span> Randomization</h4>
<p>The order and timing of experimental events was determined pseudo-randomly by the Mersenne Twister pseudorandom number generator, initialized in a way that ensures registration time-locking <span class="citation">(Mazor, Mazor, &amp; Mukamel, 2019)</span>.</p>
</div>
</div>
<div id="data-analysis-1" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Data analysis</h3>
<p>We used R [Version 4.0.5; <span class="citation">R Core Team (2019)</span>] and the R-packages <em>BayesFactor</em> [Version 0.9.12.4.2; <span class="citation">Richard D. Morey &amp; Rouder (2018)</span>], <em>broom</em> [Version 0.7.9; <span class="citation">Robinson &amp; Hayes (2020)</span>], <em>cowplot</em> [Version 1.1.1; <span class="citation">Wilke (2019)</span>], <em>dplyr</em> [Version 1.0.7; <span class="citation">Wickham, François, Henry, &amp; Müller (2020)</span>], <em>ggplot2</em> [Version 3.3.5; <span class="citation">Wickham (2016)</span>], <em>lmerTest</em> [Version 3.1.3; <span class="citation">Kuznetsova, Brockhoff, &amp; Christensen (2017)</span>], <em>lsr</em> [Version 0.5; <span class="citation">Navarro (2015)</span>], <em>MESS</em> [Version 0.5.7; <span class="citation">Ekstrøm (2019)</span>], <em>papaja</em> [Version 0.1.0.9997; <span class="citation">Aust &amp; Barth (2020)</span>], <em>pracma</em> [Version 2.3.3; <span class="citation">Borchers (2019)</span>], <em>pwr</em> [Version 1.3.0; <span class="citation">Champely (2020)</span>], and <em>tidyr</em> [Version 1.1.3; <span class="citation">Wickham &amp; Henry (2020)</span>] for all our analyses.</p>
<p>For each of the six stimulus pairs [<span class="math inline">\(S_1\)</span>, <span class="math inline">\(S_2\)</span>], we tested the following hypotheses:</p>
<ol style="list-style-type: decimal">
<li><strong>Hypothesis 1</strong>: Subjective confidence is higher for <span class="math inline">\(S_1\)</span> responses than for <span class="math inline">\(S_2\)</span> responses.</li>
</ol>
<p>For each of the six stimulus pairs, we tested the null hypothesis that subjective confidence for <span class="math inline">\(S_1\)</span> responses is equal to or lower than subjective confidence for the feature-absent stimulus (<span class="math inline">\(H_o: conf_{S_1}\leq Conf_{S_2}\)</span>).</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Hypothesis 2</strong>: Metacognitive sensitivity, measured as the area under the response conditional type 2 ROC curves, is higher for <span class="math inline">\(S_1\)</span> responses than for <span class="math inline">\(S_2\)</span> responses.</li>
</ol>
<p>For each of the six stimulus pairs, we tested the null hypothesis that metacognitive sensitivity for <span class="math inline">\(S_1\)</span> responses is equal to or lower than metacognitive sensitivity for the <span class="math inline">\(S_2\)</span> responses (<span class="math inline">\(H_o: auROC_{S_1}\leq auROC_{S_2}\)</span>).</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Hypothesis 3</strong>: Metacognitive sensitivity, measured as the area under the response conditional type 2 ROC curves, is higher for <span class="math inline">\(S_1\)</span> responses than for <span class="math inline">\(S_2\)</span> responses, to a greater extent than expected from an equivalent equal-variance SDT model.</li>
</ol>
<p>For each of the six stimulus pairs, we tested the null hypothesis that difference between metacognitive sensitivities for <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> responses is lower than the difference expected from an equivalent equal-variance SDT model (<span class="math inline">\(H_o: (auROC_{S_1}-auROC_{S_2})\leq (\widehat{auROC}_{S_1}-\widehat{auROC}_{S_2})\)</span> where <span class="math inline">\(\widehat{auROC}\)</span> is the expected auROC under an equal variance SDT model with equal sensitivity, criterion, and distribution of confidence ratings in incorrect responses).</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Hypothesis 4</strong>: <span class="math inline">\(S_1\)</span> responses are faster on average than <span class="math inline">\(S_2\)</span> responses.</li>
</ol>
<p>For each of the six stimulus pairs, we tested the null hypothesis that log-transformed response times for <span class="math inline">\(S_1\)</span> responses are equal to or higher than log-transformed response times for <span class="math inline">\(S_2\)</span> responses (<span class="math inline">\(H_o: log(RT_{S_1})\geq log(RT_{S_2})\)</span>).</p>
<p>Hypotheses 1 and 2 correspond to the effects of stimulus type on metacognitive bias and metacognitive sensitivity, respectively. Although these two measures are theoretically independent, both bias and sensitivity are found to vary between detection ‘yes’ and ‘no’ responses.</p>
<p>Based on pilot data and previous experiments examining near-threshold perceptual detection and discrimination, we did not expect a response bias (such that the probability of responding <span class="math inline">\(S_1\)</span> is significantly different from 0.5 across participants). However, such a response bias, if found, may bias metacognitive asymmetry estimates as measured with response conditional type 2 ROC curves. Hypothesis 3 was designed to confirm that metacognitive asymmetry is higher than that expected from an equivalent equal-variance SDT model with the same response bias, sensitivity, and distribution of confidence ratings in incorrect responses as in the actual data. We interpreted conflicting results for Hypotheses 2 and 3 as evidence for a metacognitive asymmetry that is driven or masked by a response bias.</p>
<p>Hypothesis 4 is motivated by two observations from previous studies. First, detection ‘yes’ responses are faster than detection ‘no’ responses <span class="citation">(Mazor, Friston, &amp; Fleming, 2020)</span>. And second, when participants are not under strict time pressure, reaction time inversely scales with confidence <span class="citation">(Calder-Travis, Charles, Bogacz, &amp; Yeung, 2020; Henmon, 1911; Moran, Teodorescu, &amp; Usher, 2015; Pleskac &amp; Busemeyer, 2010)</span>. Based on these findings, if <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> responses are similar to detection ‘yes’ and ‘no’ responses not only in explicit confidence judgments, but also in response times, we should also expect a response time difference for these stimulus pairs.</p>
</div>
<div id="analysis-plan" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Dependent variables and analysis plan</h3>
<p>Response conditional type 2 ROC (rcROC) curves were extracted by plotting the empirical cumulative distribution of confidence ratings for correct responses against the same cumulative distribution for incorrect responses. This was done separately for the two responses <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>, resulting in two curves. The area under the rcROC curve is a measure of metacognitive sensitivity <span class="citation">(Fleming &amp; Lau, 2014)</span>. The difference between the areas for the two responses is a measure of metacognitive asymmetry <span class="citation">(Meuwese, Loon, Lamme, &amp; Fahrenfort, 2014)</span>. This difference was used to test Hypothesis 2.</p>
<p>In order to test hypothesis 3, SDT-derived rcROC curves were plotted in the following way. For each response, we plotted the empirical cumulative distribution for incorrect responses on the x axis against the cumulative distribution for correct responses that would be expected in an equal-variance SDT model with matching sensitivity and response bias on the y axis. The difference between the areas of these theoretically derived rcROC curves was compared against the difference between the true rcROC curves.</p>
<p>For visualization purposes only, confidence ratings were divided into 20 bins, tailored for each participant to cover their dynamic range of confidence ratings.</p>
<p>For each of the six experiments, Hypotheses 1-4 were tested using a one tailed t-test at the group level with <span class="math inline">\(\alpha=0.05\)</span>. The summary statistic at the single subject level was difference in mean confidence between <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> responses for Hypothesis 1, difference in area under the rcROC curve between <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> responses (<span class="math inline">\(\Delta AUC\)</span>) for Hypothesis 2, difference in <span class="math inline">\(\Delta AUC\)</span> between true confidence distributions and SDT-derived confidence distributions for hypothesis 3, and difference in mean log response time between <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> responses for Hypothesis 4.</p>
<p>In addition, a Bayes factor was computed using the BayesFactor R package <span class="citation">(Richard D. Morey, Rouder, Jamil, &amp; Morey, 2015)</span> and using a Jeffrey-Zellner-Siow (Cauchy) Prior with an rscale parameter of 0.65, representative of the similar standardized effect sizes we observe for Hypotheses 1-4 in our pilot data.</p>
<p>We based our inference on the resulting Bayes Factors.</p>
</div>
<div id="statistical-power" class="section level3" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Statistical power</h3>
<p>Statistical power calculations were performed using the R-pwr packages pwr <span class="citation">(Champely, 2020)</span> and PowerTOST <span class="citation">(Labes, Schütz, Lang, &amp; Labes, 2020)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Hypothesis 1 (MEAN CONFIDENCE): With 106 participants, we had statistical power of 95% to detect effects of size 0.32, which is less than the standardized effect size we observed for confidence in our pilot sample (<span class="math inline">\(d=0.66\)</span>).</p></li>
<li><p>Hypothesis 2 (METACOGNITIVE ASYMMETRY): With 106 participants, we had statistical power of 95% to detect effects of size 0.32, which is less than the standardized effect size we observed for metacognitive sensitivity in our pilot sample (<span class="math inline">\(d=0.73\)</span>).</p></li>
<li><p>Hypothesis 3 (METACOGNITIVE ASYMMETRY: CONTROL): With 106 participants, we had statistical power of 95% to detect effects of size 0.32, which is less than the standardized effect size we observed for metacognitive sensitivity, controlling for response bias, in our pilot sample (<span class="math inline">\(d=0.81\)</span>).</p></li>
<li><p>Hypothesis 4 (RESPONSE TIME): With 106 participants, we had statistical power of 95% to detect effects of size 0.32, which is less than the standardized effect size we observed for response time in our pilot sample (<span class="math inline">\(d=0.61\)</span>).</p></li>
</ol>
<p>Finally, in case that the true effect size equals 0, a Bayes Factor with our chosen prior for the alternative hypothesis will support the null in 95 out of 100 repetitions, and will support the null with a <span class="math inline">\(BF_{01}\)</span> higher than 3 in 79 out of 100 repetitions. In a case where the true effect size is sampled from a Cauchy distribution with a scale factor of 0.65, a Bayes Factor with our chosen prior for the alternative hypothesis will support the alternative hypothesis in 76 out of 100 repetitions, support the alternative hypothesis with a <span class="math inline">\(BF_{10}\)</span> higher than 3 in 70 out of 100 repetitions, and support the null hypothesis with a <span class="math inline">\(BF_{01}\)</span> higher than 3 in 15 out of 100 hypotheses <span class="citation">(based on an adaptation of simulation code from Lakens, 2016)</span>.</p>
<div id="rejection-criteria-1" class="section level4 unnumbered">
<h4>Rejection criteria</h4>
<p>Participants were excluded for performing below 60% accuracy, for having extremely fast or slow reaction times (below 250 milliseconds or above 5 seconds in more than 25% of the trials), and for failing the comprehension check. Finally, for type-2 ROC curves to be generated, some responses must be incorrect, and for them to be informative some variability in confidence ratings is necessary. Thus, participants who committed less than two of each error type (for example, mistaking a <em>Q</em> for an <em>O</em> and mistaking an <em>O</em> for a <em>Q</em>), or who reported less than two different confidence levels for each of the two responses were excluded from all analyses.</p>
<p>Trials with response time below 250 milliseconds or above 5 seconds were excluded.</p>
</div>
</div>
</div>
<div id="data-availability" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Data availability</h2>
<p>All raw data is fully available on OSF and on the study’s GitHub respository: <a href="https://github.com/matanmazor/asymmetry" class="uri">https://github.com/matanmazor/asymmetry</a>.</p>
</div>
<div id="code-availability" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Code availability</h2>
<p>All analysis code is openly shared on the study’s GitHub repository: <a href="https://github.com/matanmazor/asymmetry" class="uri">https://github.com/matanmazor/asymmetry</a>. For complete reproducibility, the RMarkdown file used to generate the final version of the manuscript, including the generation of all figures and extraction of all test statistics, is also available on our GitHub repository.</p>
</div>
<div id="deviations" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Deviations from pre-registration</h2>
<ul>
<li><p><em>Stimulus used for backward masking</em>: We planned to use the same stimulus (the letter <em>Z</em>) for backward masking in all six experiments. This mask was effective in Experiments 1 and 2, but in Experiment 3 overly high accuracy levels indicated that for these stimuli the mask was not salient enough. For a subset of participants in Exp. 3, an overlay of all 7 stimuli from experiments 3-6 (vertical, tilted, and curved lines, upward-tilted and downward-tilted cubes, and normal and flipped Ns) was used. For the remaining participants and experiments, we used four dollar signs as our mask. See Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-trialstructure">5.2</a> for depictions of the three masks.</p></li>
<li><p><em>Rejection criteria</em>: In our pre-registration we explain that informative rcROC curves can only be generated if participants make errors. When analyzing the data we came to realize that an additional prerequisite for rcROC curves to be informative is that the variance in confidence ratings is higher than zero, otherwise the curve is diagonal. We therefore required that participants report at least two different confidence levels for each response. Participants that did not meet this additional criterion were excluded from all analyses.</p></li>
<li><p><em>Monetary compensation</em>: For some of the experiments, we noticed that participants completed the experiment more quickly than what we had originally estimated. We therefore reduced our offered payment for some of the experiments, while maintaining a median hourly wage of £6 or higher.</p></li>
</ul>
</div>
<div id="results-8" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Results</h2>
<p>A summary of the results from all six experiments is available in section <a href="5-ch-asymmetry.html#asymmetry-summary">5.6.7</a> and in Figures <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, <a href="5-ch-asymmetry.html#fig:asymmetry-all-rcROCs">5.4</a> and <a href="5-ch-asymmetry.html#fig:asymmetry-summary">5.5</a>.</p>
<div id="experiment-1-q-vs.-o" class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Experiment 1: <em>Q</em> vs. <em>O</em></h3>
<p>In Experiment 1, we examined discrimination judgments between the two letters <em>Q</em> and <em>O</em>. Based on a search asymmetry for these letters [<em>Q</em>s are found faster than <em>O</em>s than vice-versa; <span class="citation">A. Treisman &amp; Souther (1985)</span>], we hypothesized that a similar asymmetry would emerge in subjective confidence judgments, such that metacognitive sensitivity for <em>Q</em> responses will be higher than for <em>O</em> responses. We used the letter <em>Z</em> as our backward mask.</p>
<p>205 participants were recruited from Prolific for Experiment 1.</p>
<p>Median completion time was 13.12 minutes. Mean proportion correct was 0.74. Participants reported seeing an <em>O</em> on 47% of trials. In a deviation from our pre-registration, we excluded 9 participants for having zero variance in their confidence ratings for at least one of the two responses (see Section <a href="5-ch-asymmetry.html#deviations">5.5</a>). Overall we excluded 71 participants based on our exclusion criteria, leaving 134 participants for the main analysis. Due to a technical error in data collection, this figure is higher than that specified in our preregistration document (N=106). Going forward, only data from included participants is analyzed.</p>
<p>Mean proportion correct among the included participants was <span class="math inline">\(M = 0.74\)</span>, 95% CI <span class="math inline">\([0.73\)</span>, <span class="math inline">\(0.75]\)</span>. Mean SOA in the last trial was <span class="math inline">\(M = 47.50\)</span>, 95% CI <span class="math inline">\([39.39\)</span>, <span class="math inline">\(55.61]\)</span>. Participants showed no consistent bias in their responses (quantified as the probability of a ‘Q’ response minus 0.5; <span class="math inline">\(M = 0.02\)</span>, 95% CI <span class="math inline">\([0.00\)</span>, <span class="math inline">\(0.04]\)</span>). On a scale of 0 to 1, mean confidence level was <span class="math inline">\(M = 0.49\)</span>, 95% CI <span class="math inline">\([0.45\)</span>, <span class="math inline">\(0.53]\)</span>. Confidence was higher for correct than for incorrect responses (<span class="math inline">\(M_d = 0.15\)</span>, 95% CI <span class="math inline">\([0.13\)</span>, <span class="math inline">\(0.17]\)</span>, <span class="math inline">\(t(133) = 14.85\)</span>, <span class="math inline">\(p &lt; .001\)</span>).</p>
<p><em>Hypothesis 1</em>: In line with our hypothesis, confidence was generally higher for <em>Q</em> (feature present) responses than for <em>O</em> (feature absent) responses (<span class="math inline">\(t(133) = 7.52\)</span>, <span class="math inline">\(p &lt; .001\)</span>; Cohen’s d = 0.65; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 1.07 \times 10^{9}\)</span>; see Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 1).</p>
<p><em>Hypothesis 2</em>: In order to measure metacognitive asymmetry, we extracted the response conditional type 2 ROC (rcROC) curves for the two responses (<em>Q</em> and <em>O</em>) in the discrimination task. This was done by plotting the cumulative distribution of confidence ratings (high to low) for correct responses against the same distribution for incorrect responses. The area under the rcROC curve (auROC2) was then taken as a measure of metacognitive sensitivity <span class="citation">(Kanai, Walsh, &amp; Tseng, 2010; Meuwese, Loon, Lamme, &amp; Fahrenfort, 2014)</span>. In line with our hypothesis, auROC2 for <em>Q</em> responses (<span class="math inline">\(M = 0.72\)</span>, 95% CI <span class="math inline">\([0.70\)</span>, <span class="math inline">\(0.74]\)</span>) was higher than for <em>O</em> responses (<span class="math inline">\(M = 0.68\)</span>, 95% CI <span class="math inline">\([0.66\)</span>, <span class="math inline">\(0.70]\)</span>; <span class="math inline">\(t(133) = 2.96\)</span>, <span class="math inline">\(p = .002\)</span>; Cohen’s d = 0.26; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 6.56\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-rcROCs">5.4</a>, panel 1), similar to the documented metacognitive asymmetry for detection judgments.</p>
<p><em>Hypothesis 3</em>: Metacognitive asymmetry was not significantly higher than what is expected based on an equal-variance SDT model with the same response bias and sensitivity as the subjects (<span class="math inline">\(t(133) = 0.97\)</span>, <span class="math inline">\(p = .167\)</span>; Cohen’s d=0.08). A Bayes Factor indicated that our results are more likely under a model that assumes no additional metacognitive asymmetry (<span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 6.07\)</span>).</p>
<p><em>Hypothesis 4</em>: In line with our hypothesis, <em>Q</em> responses were faster on average than <em>O</em> responses by 37 ms. (<span class="math inline">\(t(133) = -2.99\)</span>, <span class="math inline">\(p = .002\)</span> ; Cohen’s d = 0.26; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 7.05\)</span>; see Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 1).</p>
<p>In summary, in Experiment 1 we found that <em>Q</em> responses were faster and accompanied by higher subjective confidence, in line with a processing advantage for feature-presence. Metacognitive asymmetry however did not go beyond what is expected from an equal-variance SDT model for these stimuli, taking into account response biases.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:asymmetry-all-distributions"></span>
<img src="figure/asymmetry/hists.png" alt="Reaction time and confidence distributions for Experiments 1-6. Box edges and central lines represent the 25, 50 and 75 quantiles. Whiskers cover data points within four inter-quartile ranges around the median. Black lines connect the median values for the two responses. Stars represent significance in a two-sided t-test: **: p&lt;0.01, ***: p&lt;0.001" width="100%" />
<p class="caption">
Figure 5.3: Reaction time and confidence distributions for Experiments 1-6. Box edges and central lines represent the 25, 50 and 75 quantiles. Whiskers cover data points within four inter-quartile ranges around the median. Black lines connect the median values for the two responses. Stars represent significance in a two-sided t-test: **: p&lt;0.01, ***: p&lt;0.001
</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:asymmetry-all-rcROCs"></span>
<img src="figure/asymmetry/rcROCs.png" alt="Response conditional type 2 ROC (rcROC) curves for Experiments 1-6. The area under the curve is a measure of metacognitive sensitivity. Error bars stand for the standard error of the mean. For illustration, the response conditional ROC (rcROC) curves of the first 20 participants of each Experiment are plotted in low opacity. Below each ROC: distributions of the area under the curve for the two responses, across participants. Same conventions as Fig. 5.3. Stars represent significance in a two-sided t-test: *: p&lt;0.05, **: p&lt;0.01, ***: p&lt;0.001" width="100%" />
<p class="caption">
Figure 5.4: Response conditional type 2 ROC (rcROC) curves for Experiments 1-6. The area under the curve is a measure of metacognitive sensitivity. Error bars stand for the standard error of the mean. For illustration, the response conditional ROC (rcROC) curves of the first 20 participants of each Experiment are plotted in low opacity. Below each ROC: distributions of the area under the curve for the two responses, across participants. Same conventions as Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>. Stars represent significance in a two-sided t-test: *: p&lt;0.05, **: p&lt;0.01, ***: p&lt;0.001
</p>
</div>
</div>
<div id="experiment-2-c-vs.-o" class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Experiment 2: C vs. O</h3>
<p>In Experiment 2, we looked at discrimination judgments between the two letters <em>C</em> and <em>O</em>. Based on a search asymmetry for these letters [<em>C</em>s are found faster among <em>O</em>s than vice versa; <span class="citation">A. Treisman &amp; Souther (1985)</span>; <span class="citation">Takeda &amp; Yagi (2000)</span>; <span class="citation">A. Treisman &amp; Gormican (1988)</span>], we hypothesized that a similar asymmetry would emerge in subjective confidence judgments, such that metacognitive sensitivity for perceiving a <em>C</em> will be higher than for perceiving an <em>O</em>. We used the letter <em>Z</em> as our backward mask.</p>
<p>143 participants were recruited from Prolific for Experiment 2.</p>
<p>Median completion time was 12.80 minutes. Mean proportion correct was 0.75, and participants reported seeing an <em>O</em> on 43% of trials. In a deviation from our pre-registration, we excluded 8 participants for having zero variance in their confidence ratings for at least one of the two responses (see Section <a href="5-ch-asymmetry.html#deviations">5.5</a>). Overall we excluded 37 participants, leaving 106 participants for the main analysis. Going forward, only data from included participants is analyzed.</p>
<p>Mean proportion correct among included participants was <span class="math inline">\(M = 0.74\)</span>, 95% CI <span class="math inline">\([0.73\)</span>, <span class="math inline">\(0.75]\)</span>. The mean SOA of the last trial was <span class="math inline">\(M = 40.18\)</span>, 95% CI <span class="math inline">\([34.37\)</span>, <span class="math inline">\(46.00]\)</span>. Participants showed a consistent bias toward reporting a <em>C</em> rather than an <em>O</em> (<span class="math inline">\(M = 0.07\)</span>, 95% CI <span class="math inline">\([0.05\)</span>, <span class="math inline">\(0.08]\)</span>). On a scale of 0 to 1, mean confidence level was <span class="math inline">\(M = 0.52\)</span>, 95% CI <span class="math inline">\([0.48\)</span>, <span class="math inline">\(0.56]\)</span>. Confidence was higher for correct than for incorrect responses (<span class="math inline">\(M_d = 0.17\)</span>, 95% CI <span class="math inline">\([0.15\)</span>, <span class="math inline">\(0.19]\)</span>, <span class="math inline">\(t(105) = 15.05\)</span>, <span class="math inline">\(p &lt; .001\)</span>).</p>
<p><em>Hypothesis 1</em>: In line with our hypothesis, confidence was generally higher for <em>C</em> (feature present) responses than for <em>O</em> (feature absent) responses (<span class="math inline">\(M_d = 0.05\)</span>, 95% CI <span class="math inline">\([0.03\)</span>, <span class="math inline">\(\infty]\)</span>, <span class="math inline">\(t(105) = 3.59\)</span>, <span class="math inline">\(p &lt; .001\)</span>; Cohen’s d = 0.35; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 42.62\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 2).</p>
<p><em>Hypothesis 2</em>: Opposite to our prediction, auROC2 for <em>C</em> responses (<span class="math inline">\(M = 0.70\)</span>, 95% CI <span class="math inline">\([0.68\)</span>, <span class="math inline">\(0.72]\)</span>) was <em>lower</em> than for <em>O</em> responses (<span class="math inline">\(M = 0.75\)</span>, 95% CI <span class="math inline">\([0.73\)</span>, <span class="math inline">\(0.78]\)</span>; <span class="math inline">\(t(105) = -3.53\)</span>, <span class="math inline">\(p &gt; .999\)</span>; Cohen’s d = 0.34; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-rcROCs">5.4</a>, panel 2.). Bayes Factor strongly supported the alternative (<span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 35.19\)</span>). Note that our prior on effect sizes was symmetric around zero, such that support for the alternative is obtained for negative, as well as positive effects.</p>
<p><em>Hypothesis 3</em>: Metacognitive sensitivity for <em>C</em> responses was still higher than for <em>O</em> responses after controlling for bias (Cohen’s d=0.49; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 6.46 \times 10^{3}\)</span>).</p>
<p><em>Hypothesis 4</em>: Contrary to our hypothesis, response times for <em>C</em> and for <em>O</em> responses were highly similar, with a median difference of 6 ms. (<span class="math inline">\(t(105) = 0.01\)</span>, <span class="math inline">\(p = .504\)</span> ; Cohen’s d = 0.00; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 8.57\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 2).</p>
<p>In summary, in Experiment 2 we found a dissociation between our two confidence-related measures. As we hypothesized, participants were generally more confident in their <em>C</em> (feature present) responses, but their metacognitive sensitivity was higher following <em>O</em> (feature absent) responses. We found no reliable difference in response times between these two responses.</p>
</div>
<div id="experiment-3-tilted-vs.-vertical-lines" class="section level3" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Experiment 3: tilted vs. vertical lines</h3>
<p>In Experiment 3, we looked at discrimination judgments between tilted and vertical lines. Based on a search asymmetry for these stimuli [tilted lines are found faster among vertical lines than vice versa; <span class="citation">A. Treisman &amp; Gormican (1988)</span>], we hypothesized that a similar asymmetry would emerge in subjective confidence judgments, such that metacognitive sensitivity for perceiving a tilted line will be higher than for perceiving a vertical line. As described in section <a href="5-ch-asymmetry.html#deviations">5.5</a>, too high accuracy in the first participants led us to change our masking stimulus, first to an overlay of all stimuli and then to four dollar signs. We present here the combined results from these two cohorts of participants. The results were qualitatively similar in the two cohorts.</p>
<p>304 participants were recruited from Prolific for Experiment 3. Due to shorter than expected completion times in the first 94 participants, the remaining participants were paid £1.25, equivalent to an hourly wage of £6.</p>
<p>Median completion time was 12.43 minutes. Mean proportion correct was 0.86, and participants reported seeing a vertical line on 44% of trials. In a deviation from our pre-registration, we excluded 25 participants for having zero variance in their confidence ratings for at least one of the two responses (see Section <a href="5-ch-asymmetry.html#deviations">5.5</a>). Overall we excluded 198 participants, leaving 106 participants for the main analysis. Going forward, only data from included participants is analyzed.</p>
<p>Mean proportion correct among included participants was <span class="math inline">\(M = 0.79\)</span>, 95% CI <span class="math inline">\([0.78\)</span>, <span class="math inline">\(0.81]\)</span>. The mean SOA of the last trial was <span class="math inline">\(M = 30.83\)</span>, 95% CI <span class="math inline">\([25.99\)</span>, <span class="math inline">\(35.68]\)</span>. Participants showed a consistent bias toward reporting a tilted rather than a vertical line (<span class="math inline">\(M = 0.06\)</span>, 95% CI <span class="math inline">\([0.04\)</span>, <span class="math inline">\(0.08]\)</span>). On a scale of 0 to 1, mean confidence level was <span class="math inline">\(M = 0.61\)</span>, 95% CI <span class="math inline">\([0.56\)</span>, <span class="math inline">\(0.65]\)</span>. Confidence was higher for correct than for incorrect responses (<span class="math inline">\(M_d = 0.18\)</span>, 95% CI <span class="math inline">\([0.15\)</span>, <span class="math inline">\(0.20]\)</span>, <span class="math inline">\(t(105) = 13.42\)</span>, <span class="math inline">\(p &lt; .001\)</span>).</p>
<p><em>Hypothesis 1</em>: In line with our hypothesis, confidence was generally higher for tilted lines (feature present) responses than for vertical lines (feature absent) responses (<span class="math inline">\(M_d = 0.12\)</span>, 95% CI <span class="math inline">\([0.09\)</span>, <span class="math inline">\(\infty]\)</span>, <span class="math inline">\(t(105) = 7.18\)</span>, <span class="math inline">\(p &lt; .001\)</span>; Cohen’s d = 0.70; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 8.89 \times 10^{7}\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 3).</p>
<p><em>Hypothesis 2</em>: Contrary to our prediction, Bayes Factor analysis did not provide evidence for or against a difference in auROC2 between reports of seeing a tilted line (<span class="math inline">\(M = 0.76\)</span>, 95% CI <span class="math inline">\([0.74\)</span>, <span class="math inline">\(0.78]\)</span>) and reports of seeing a vertical line (<span class="math inline">\(M = 0.73\)</span>, 95% CI <span class="math inline">\([0.70\)</span>, <span class="math inline">\(0.75]\)</span>; Cohen’s d = 0.18; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 1.59\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-rcROCs">5.4</a>, panel 3.). A difference in metacognitive sensitivity was however significant in a standard t-test (<span class="math inline">\(t(105) = 1.88\)</span>, <span class="math inline">\(p = .031\)</span>). With a sample size of 106, a one-tailed t-test is significant for observed effect sizes of 0.16 standard deviations or higher. In contrast, for our choice of a scale factor, a Bayes Factor is higher than 3 for observed standardized effect sizes of <span class="math inline">\(0.26\)</span> standard deviations or higher. Effect sizes that fall between 0.16 and <span class="math inline">\(0.26\)</span> are then significant in a t-test, with no conclusive evidence in a Bayes Factor analysis. A robustness region analysis revealed that no scale factor would have led to the conclusion that auROC2s for the two responses are different with <span class="math inline">\(BF_{10}&gt;3\)</span>. See Supplementary Figure <a href="F-supp.-materials-for-ch.-5.html#fig:app5-RR">F.1</a> for a full Robustness Region plot <span class="citation">(Dienes, 2019)</span>.</p>
<p><em>Hypothesis 3</em>: A Bayes Factor analysis did not provide evidence for or against metacognitive asymmetry when controlling for response bias and sensitivity (<span class="math inline">\(t(105) = -0.70\)</span>, <span class="math inline">\(p = .759\)</span>; Cohen’s d=0.07; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 6.74\)</span>).</p>
<p><em>Hypothesis 4</em>: In line with our hypothesis, response times for ‘tilted’ responses were faster than response times for ‘vertical’ responses, with a median difference of 68 ms. (<span class="math inline">\(t(105) = -5.82\)</span>, <span class="math inline">\(p &lt; .001\)</span> ; Cohen’s d = 0.56; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 1.83 \times 10^{5}\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 3).</p>
<p>In summary, in Experiment 3 we found that ‘tilted’ (feature present) responses were faster and accompanied by higher subjective confidence that ‘vertical’ (feature absent) responses, with no difference in metacognitive sensitivity between the two responses.</p>
</div>
<div id="experiment-4-curved-vs.-straight-lines" class="section level3" number="5.6.4">
<h3><span class="header-section-number">5.6.4</span> Experiment 4: curved vs. straight lines</h3>
<p>In Experiment 4, we looked at discrimination judgments between curved and vertical lines. Based on a search asymmetry for these stimuli [curved lines are found faster among vertical lines than vice versa; <span class="citation">A. Treisman &amp; Gormican (1988)</span>], we hypothesized that a similar asymmetry would emerge in subjective confidence judgments, such that metacognitive sensitivity for perceiving a tilted line will be higher than for perceiving an vertical line. We used four dollar signs ($ $ $ $) as our mask.</p>
<p>211 participants were recruited from Prolific for Experiment 4. Due to shorter than expected completion times in previous experiments, participants were paid £1.25, equivalent to an hourly wage of £6.</p>
<p>Median completion time was 12.08 minutes. Mean proportion correct was 0.84, and participants reported seeing a straight line on 44% of trials. In a deviation from our pre-registration, we excluded 18 participants for having zero variance in their confidence ratings for at least one of the two responses (see Section <a href="5-ch-asymmetry.html#deviations">5.5</a>). Overall we excluded 104 participants, leaving 107 participants for the main analysis. Going forward, only data from included participants is analyzed.</p>
<p>Mean proportion correct among included participants was <span class="math inline">\(M = 0.79\)</span>, 95% CI <span class="math inline">\([0.77\)</span>, <span class="math inline">\(0.80]\)</span>. The mean SOA of the last trial was <span class="math inline">\(M = 28.01\)</span>, 95% CI <span class="math inline">\([24.22\)</span>, <span class="math inline">\(31.79]\)</span>. Participants showed a consistent bias toward reporting a curved rather than a vertical line (<span class="math inline">\(M = 0.06\)</span>, 95% CI <span class="math inline">\([0.04\)</span>, <span class="math inline">\(0.07]\)</span>). On a scale of 0 to 1, mean confidence level was <span class="math inline">\(M = 0.57\)</span>, 95% CI <span class="math inline">\([0.53\)</span>, <span class="math inline">\(0.61]\)</span>. Confidence was higher for correct than for incorrect responses (<span class="math inline">\(M_d = 0.21\)</span>, 95% CI <span class="math inline">\([0.18\)</span>, <span class="math inline">\(0.24]\)</span>, <span class="math inline">\(t(106) = 14.96\)</span>, <span class="math inline">\(p &lt; .001\)</span>).</p>
<p><em>Hypothesis 1</em>: In line with our hypothesis, confidence was generally higher for curved lines (feature present) responses than for straight lines (feature absent) responses (<span class="math inline">\(M_d = 0.12\)</span>, 95% CI <span class="math inline">\([0.09\)</span>, <span class="math inline">\(\infty]\)</span>, <span class="math inline">\(t(106) = 8.25\)</span>, <span class="math inline">\(p &lt; .001\)</span>; Cohen’s d = 0.80; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 1.61 \times 10^{10}\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 4).</p>
<p><em>Hypothesis 2</em>: Contrary to our prediction, auROC2 for reports of seeing a curved line (<span class="math inline">\(M = 0.76\)</span>, 95% CI <span class="math inline">\([0.73\)</span>, <span class="math inline">\(0.78]\)</span>) was similar to auROC2 for reports of seeing a straight line (<span class="math inline">\(M = 0.75\)</span>, 95% CI <span class="math inline">\([0.73\)</span>, <span class="math inline">\(0.78]\)</span>; <span class="math inline">\(t(106) = 0.30\)</span>, <span class="math inline">\(p = .382\)</span>; Cohen’s d = 0.03; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 8.23\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-rcROCs">5.4</a>, panel 4.).</p>
<p><em>Hypothesis 3</em>: (The lack of) metacognitive asymmetry was not different from what would be expected based on an equal-variance SDT model with the same response bias and sensitivity (<span class="math inline">\(t(106) = -1.93\)</span>, <span class="math inline">\(p = .972\)</span>; Cohen’s d=0.19; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 1.45\)</span>).</p>
<p><em>Hypothesis 4</em>: In line with our hypothesis, response times for ‘curved’ responses were faster than response times for ‘straight’ responses, with a median difference of 51 ms (<span class="math inline">\(t(106) = -4.36\)</span>, <span class="math inline">\(p &lt; .001\)</span> ; Cohen’s d = 0.42; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 558.55\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 4).</p>
<p>In summary, similar to Experiment 3, ‘curved’ (feature-present) responses were faster and accompanied by higher subjective confidence than ‘straight’ (feature absent) responses. However, similar to the results of Experiment 3, here also we did not find a metacognitive asymmetry for these stimuli.</p>
</div>
<div id="experiment-5-upward-tilted-vs.-downward-tilted-cubes" class="section level3" number="5.6.5">
<h3><span class="header-section-number">5.6.5</span> Experiment 5: upward-tilted vs. downward-tilted cubes</h3>
<p>In Experiment 5, we looked at discrimination judgments between upward-tilted and downward-tilted cubes. Based on a search asymmetry for these stimuli [upward-tilted cubes are found faster among downward-tilted cubes than vice versa, in line with an expectation to see objects on the ground and not floating in space; <span class="citation">Von Grünau &amp; Dubé (1994)</span>], we hypothesized that a similar asymmetry would emerge in subjective confidence judgments, such that metacognitive sensitivity for perceiving an upward-tilted cube will be higher than for perceiving a downward-tilted cube. We used four dollar signs ($ $ $ $) as our mask.</p>
<p>162 participants were recruited from Prolific for Experiment 5.</p>
<p>Median completion time was 13.30 minutes. Mean proportion correct was 0.79, and participants reported seeing a downward-tilted cube on 51% of trials. In a deviation from our pre-registration, we excluded 11 participants for having zero variance in their confidence ratings for at least one of the two responses (see Section <a href="5-ch-asymmetry.html#deviations">5.5</a>). Overall we excluded 56 participants, leaving 106 participants for the main analysis. Going forward, only data from included participants is analyzed.</p>
<p>Mean proportion correct among included participants was <span class="math inline">\(M = 0.77\)</span>, 95% CI <span class="math inline">\([0.76\)</span>, <span class="math inline">\(0.78]\)</span>. The mean SOA of the last trial was <span class="math inline">\(M = 29.51\)</span>, 95% CI <span class="math inline">\([23.20\)</span>, <span class="math inline">\(35.81]\)</span>. Participants showed no consistent response bias (<span class="math inline">\(M = -0.01\)</span>, 95% CI <span class="math inline">\([-0.03\)</span>, <span class="math inline">\(0.00]\)</span>). On a scale of 0 to 1, mean confidence level was <span class="math inline">\(M = 0.55\)</span>, 95% CI <span class="math inline">\([0.51\)</span>, <span class="math inline">\(0.59]\)</span>. Confidence was higher for correct than for incorrect responses (<span class="math inline">\(M_d = 0.23\)</span>, 95% CI <span class="math inline">\([0.20\)</span>, <span class="math inline">\(0.26]\)</span>, <span class="math inline">\(t(105) = 13.89\)</span>, <span class="math inline">\(p &lt; .001\)</span>).</p>
<p><em>Hypothesis 1</em>: Contrary to our hypothesis, confidence was similar for upward-tilted (feature present) responses and downward-tilted (feature absent) responses (<span class="math inline">\(M_d = 0.00\)</span>, 95% CI <span class="math inline">\([-0.02\)</span>, <span class="math inline">\(\infty]\)</span>, <span class="math inline">\(t(105) = 0.12\)</span>, <span class="math inline">\(p = .452\)</span>; Cohen’s d = 0.01; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 8.51\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 5).</p>
<p><em>Hypothesis 2</em>: Contrary to our hypothesis, a Bayes Factor analysis did not provide evidence for or against a difference in auROC2 for reports of seeing an upward-tilted cube (<span class="math inline">\(M = 0.75\)</span>, 95% CI <span class="math inline">\([0.73\)</span>, <span class="math inline">\(0.77]\)</span>) and reports of seeing a downward-tilted cube (<span class="math inline">\(M = 0.72\)</span>, 95% CI <span class="math inline">\([0.70\)</span>, <span class="math inline">\(0.75]\)</span>; Cohen’s d = 0.22; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 1.38\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-rcROCs">5.4</a>, panel 5.). In contrast, a t-test revealed a significant metacognitive asymmetry, with higher metacognitive sensitivity for perceiving an upward-tilted (default-violating) cube (<span class="math inline">\(t(105) = 2.29\)</span>, <span class="math inline">\(p = .012\)</span>). See Supplementary Figure <a href="F-supp.-materials-for-ch.-5.html#fig:app5-RR">F.1</a> for a full Robustness Region plot <span class="citation">(Dienes, 2019)</span>.</p>
<p><em>Hypothesis 3</em>: (The lack of) metacognitive asymmetry was not different from what would be expected based on an equal-variance SDT model with the same response bias and sensitivity (Cohen’s d=0.22; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 1.28\)</span>). Here also, frequentist and Bayesian analyses conflicted, with a t-test revealing a significant metacogntiive advantage for upward-tilted (default violating) responses when controlling for bias (<span class="math inline">\(t(105) = 2.25\)</span>, <span class="math inline">\(p = .013\)</span>).</p>
<p><em>Hypothesis 4</em>: Contrary to our hypothesis, response times for ‘upward-tilted’ responses were similar to response times for ‘downward-tilted’ responses with a median difference of 9 ms. (<span class="math inline">\(t(105) = -0.82\)</span>, <span class="math inline">\(p = .207\)</span> ; Cohen’s d = 0.08; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 6.19\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 5).</p>
<p>In summary, in Experiment 5 we found no sign of processing asymmetry between upward and downward-tilted cubes in response-times and confidence. A significant metacognitive asymmetry was observed when using null-hypothesis significance testing, but was not supported by our Bayes Factor analysis. In accordance with our pre-registered plan to commit to the Bayes Factor analysis in interpreting the results, in what follows we interpret these findings as providing no support for a metacognitive asymmetry for upward and downward tilted cubes.</p>
</div>
<div id="experiment-6-flipped-vs.-normal-letters" class="section level3" number="5.6.6">
<h3><span class="header-section-number">5.6.6</span> Experiment 6: flipped vs. normal letters</h3>
<p>In Experiment 6, we looked at discrimination judgments between flipped and normal Ns. Based on a search asymmetry for these stimuli [flipped Ns are found faster among normal Ns than vice versa; <span class="citation">U. Frith (1974)</span>; <span class="citation">Wang, Cavanagh, &amp; Green (1994)</span>], we hypothesized that a similar asymmetry would emerge in subjective confidence judgments, such that metacognitive sensitivity for perceiving a flipped N will be higher than for perceiving a normal N. We used four dollar signs ($ $ $ $) as our mask.</p>
<p>127 participants were recruited from Prolific for Experiment 6. Due to shorter than expected completion times in previous experiments, participants were paid £1.25, equivalent to an hourly wage of £6.</p>
<p>Median completion time was 12.76 minutes. Mean proportion correct was 0.74, and participants reported seeing a normal <em>N</em> on 50% of trials. In a deviation from our pre-registration, we excluded 4 participants for having zero variance in their confidence ratings for at least one of the two responses (see Section <a href="5-ch-asymmetry.html#deviations">5.5</a>). Overall we excluded 21 participants, leaving 106 participants for the main analysis. Going forward, only data from included participants is analyzed.</p>
<p>Mean proportion correct among included participants was <span class="math inline">\(M = 0.73\)</span>, 95% CI <span class="math inline">\([0.72\)</span>, <span class="math inline">\(0.74]\)</span>. The mean SOA in the last trial was <span class="math inline">\(M = 37.26\)</span>, 95% CI <span class="math inline">\([33.07\)</span>, <span class="math inline">\(41.46]\)</span>. Participants showed no consistent response bias (<span class="math inline">\(M = 0.00\)</span>, 95% CI <span class="math inline">\([-0.02\)</span>, <span class="math inline">\(0.02]\)</span>). On a scale of 0 to 1, mean confidence level was <span class="math inline">\(M = 0.53\)</span>, 95% CI <span class="math inline">\([0.49\)</span>, <span class="math inline">\(0.57]\)</span>. Confidence was higher for correct than for incorrect responses (<span class="math inline">\(M_d = 0.17\)</span>, 95% CI <span class="math inline">\([0.15\)</span>, <span class="math inline">\(0.20]\)</span>, <span class="math inline">\(t(105) = 16.45\)</span>, <span class="math inline">\(p &lt; .001\)</span>).</p>
<p><em>Hypothesis 1</em>: Contrary to our hypothesis, confidence was <em>lower</em> for flipped (feature present) responses than for normal (feature absent) responses. This result was in the opposite direction to what we had expected, so was not significant in a one-tailed t-test (<span class="math inline">\(M_d = -0.04\)</span>, 95% CI <span class="math inline">\([-0.06\)</span>, <span class="math inline">\(\infty]\)</span>, <span class="math inline">\(t(105) = -3.32\)</span>, <span class="math inline">\(p = .999\)</span>; Cohen’s d = 0.32). However, a Bayes Factor favoured the alternative over the null (<span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 18.92\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 6).</p>
<p><em>Hypothesis 2</em>: Contrary to our hypothesis, auROC2 for reports of seeing a flipped <em>N</em> (<span class="math inline">\(M = 0.71\)</span>, 95% CI <span class="math inline">\([0.69\)</span>, <span class="math inline">\(0.73]\)</span>) was similar to auROC2 for reports of seeing a normal <em>N</em> (<span class="math inline">\(M = 0.71\)</span>, 95% CI <span class="math inline">\([0.69\)</span>, <span class="math inline">\(0.73]\)</span>; <span class="math inline">\(t(105) = 0.08\)</span>, <span class="math inline">\(p = .468\)</span>; Cohen’s d = 0.01; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 8.54\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-rcROCs">5.4</a>, panel 6.).</p>
<p><em>Hypothesis 3</em>: (The lack of) metacognitive asymmetry was not different from what would be expected based on an equal-variance SDT model with the same response bias and sensitivity (<span class="math inline">\(t(105) = 0.26\)</span>, <span class="math inline">\(p = .396\)</span>; Cohen’s d=0.03; <span class="math inline">\(\mathrm{BF}_{\textrm{01}} = 8.28\)</span>).</p>
<p><em>Hypothesis 4</em>: Contrary to our hypothesis, response times for ‘flipped’ responses were <em>slower</em> than response times for ‘normal’ responses, with a median difference of 30 ms. (<span class="math inline">\(t(105) = 2.81\)</span>, <span class="math inline">\(p = .997\)</span> ; Cohen’s d = 0.27; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 4.66\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-all-distributions">5.3</a>, panel 6).</p>
<p>In summary, in Experiment 6 we found a difference in response speed and subjective confidence in the opposite direction to what we expected, with a processing advantage for the default-complying stimulus (<em>N</em>) compared to the default-violating stimulus (flipped <em>N</em>). We found no metacognitive asymmetry for these stimuli.</p>
</div>
<div id="asymmetry-summary" class="section level3" number="5.6.7">
<h3><span class="header-section-number">5.6.7</span> Experiments 1-6: summary</h3>
<p>Overall, the pattern of results from Experiments 1-6 only partly matched our hypotheses in some cases, and stood in direct contrast to them in other cases (see fig. <a href="5-ch-asymmetry.html#fig:asymmetry-summary">5.5</a>). A reliable metacognitive asymmetry was observed only in Experiment 2, and this asymmetry was in the opposite direction to what we had predicted, with a metacognitive advantage for <em>O</em> (feature absent) over <em>C</em> (feature present) responses. A metacognitive advantage for reporting <em>Q</em> over <em>O</em>s (Exp. 1) was not reliably above what is expected based on an equal-variance signal detection model.</p>
<p>For both local and global visual features (Experiments 1-4) we observed differences in mean confidence and response times that were consistent with our hypothesis of a processing advantage for the representation of the presence compared to the absence of visual features. In Experiments 5 and 6, we tested more abstract expectation violations. In Experiment 5, discrimination between upward-tilted and downward-tilted cubes showed no asymmetry in response time and confidence. In Experiment 6, participants were less confident and slower in their reports of seeing a flipped N, contrary to our prediction that default-violating signals should be easier to perceive. We found no evidence for or against a metacognitive asymmetry in either of the experiments.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:asymmetry-summary"></span>
<img src="figure/asymmetry/summary.png" alt="Summary of results from Experiments 1-6, and from the positive-control Experiment 7" width="100%" />
<p class="caption">
Figure 5.5: Summary of results from Experiments 1-6, and from the positive-control Experiment 7
</p>
</div>
</div>
<div id="experiment-7-exploratory-grating-vs.-noise" class="section level3" number="5.6.8">
<h3><span class="header-section-number">5.6.8</span> Experiment 7 (exploratory): grating vs. noise</h3>
<p>Results from Experiments 1-6 revealed that search asymmetry is not always accompanied by an asymmetry in metacognitive sensitivity. Given that we did not observe a true metacognitive asymmetry in the expected direction for any of our stimulus pairs, we were concerned that our experimental design may have been unsuitable for detecting classical metacognitive asymmetries in detection, for example due to an insufficient number of trials, the masking procedure, or the confidence report scheme. As a positive control, we collected data for an additional experiment that more closely resembled typical detection experiments. In this experiment, participants discriminated between two stimuli: random noise and a noisy grating (presented to participants as a ‘zebra’ stimulus; see Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-rcROC7">5.6</a>). In Chapter <a href="#ch:fMRI"><strong>??</strong></a>, similar stimuli produced a robust metacognitive asymmetry between target absent (noise) and target present (noisy grating) responses <span class="citation">(Mazor, Friston, &amp; Fleming, 2020)</span>. We used black and white concentric circles as a mask. Apart from the choice of stimuli and mask, the procedure was identical to that of our pre-registered experiments.</p>
<p>127 participants were recruited from Prolific for exploratory Experiment 7. For this positive control, all four hypotheses were fulfilled.</p>
<p>Median completion time was 10.70 minutes. Mean proportion correct was 0.73, and participants reported seeing a grating on 48% of trials. Overall we excluded 36 participants, leaving 105 participants for the main analysis. Going forward, only data from included participants is analyzed.</p>
<p>Mean proportion correct among included participants was <span class="math inline">\(M = 0.76\)</span>, 95% CI <span class="math inline">\([0.74\)</span>, <span class="math inline">\(0.77]\)</span>. The mean SOA of the last trial was <span class="math inline">\(M = 53.87\)</span>, 95% CI <span class="math inline">\([38.85\)</span>, <span class="math inline">\(68.89]\)</span>. Participants showed no consistent response bias (<span class="math inline">\(M = 0.01\)</span>, 95% CI <span class="math inline">\([0.00\)</span>, <span class="math inline">\(0.03]\)</span>). On a scale of 0 to 1, mean confidence level was <span class="math inline">\(M = 0.55\)</span>, 95% CI <span class="math inline">\([0.51\)</span>, <span class="math inline">\(0.59]\)</span>. Confidence was higher for correct than for incorrect responses (<span class="math inline">\(M_d = 0.15\)</span>, 95% CI <span class="math inline">\([0.13\)</span>, <span class="math inline">\(0.17]\)</span>, <span class="math inline">\(t(104) = 12.58\)</span>, <span class="math inline">\(p &lt; .001\)</span>).</p>
<p><em>Hypothesis 1</em>: In line with our hypothesis, confidence was higher for reports of target presence than for reports of target absence (<span class="math inline">\(M_d = 0.20\)</span>, 95% CI <span class="math inline">\([0.17\)</span>, <span class="math inline">\(\infty]\)</span>, <span class="math inline">\(t(104) = 14.07\)</span>, <span class="math inline">\(p &lt; .001\)</span>; Cohen’s d = 1.37; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 4.39 \times 10^{22}\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-rcROC7">5.6</a>, right panel).</p>
<p><em>Hypothesis 2</em>: In line with our hypothesis, auROC2 for reports of target presence (<span class="math inline">\(M = 0.75\)</span>, 95% CI <span class="math inline">\([0.73\)</span>, <span class="math inline">\(0.77]\)</span>) was higher than for reports of target absence (<span class="math inline">\(M = 0.68\)</span>, 95% CI <span class="math inline">\([0.66\)</span>, <span class="math inline">\(0.70]\)</span>; <span class="math inline">\(t(104) = 5.20\)</span>, <span class="math inline">\(p &lt; .001\)</span>; Cohen’s d = 0.51; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 1.42 \times 10^{4}\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-rcROC7">5.6</a>, left panel).</p>
<p><em>Hypothesis 3</em>: In line with our hypothesis, this metacognitive asymmetry was stronger than what is expected based on an equal-variance SDT model with the same response bias and sensitivity (<span class="math inline">\(t(104) = 3.49\)</span>, <span class="math inline">\(p &lt; .001\)</span>; Cohen’s d=0.34; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 31.40\)</span>).</p>
<p><em>Hypothesis 4</em>: In line with our hypothesis, reports of target presence were faster than reports of target absence, with a median difference of 124 ms. (<span class="math inline">\(t(104) = -8.84\)</span>, <span class="math inline">\(p &lt; .001\)</span> ; Cohen’s d = 0.86; <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 2.63 \times 10^{11}\)</span>; see Figure <a href="5-ch-asymmetry.html#fig:asymmetry-rcROC7">5.6</a>, right panel).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:asymmetry-rcROC7"></span>
<img src="figure/asymmetry/results7.png" alt="rcROC curves (left panel) and confidence and reaction time distributions (right panel) for Exp. 7 (detection positive control)" width="100%" />
<p class="caption">
Figure 5.6: rcROC curves (left panel) and confidence and reaction time distributions (right panel) for Exp. 7 (detection positive control)
</p>
</div>
</div>
<div id="exploratory-analysis" class="section level3" number="5.6.9">
<h3><span class="header-section-number">5.6.9</span> Exploratory analysis</h3>
<div id="zroc-analysis" class="section level4 unnumbered">
<h4>zROC analysis</h4>
<p>In a signal-detection framework, metacognitive asymmetry appears when the signal distribution has both a higher mean and higher variance than that of the noise distribution. This unequal variance setting produces higher metacognitive sensitivity for judgments of signal presence, compared to judgments of signal absence. A direct measure for the ratio between the variances of the two distributions is the slope of the <em>type-1 zROC curve</em>. A zROC curve is constructed by applying the inverse of the normal cumulative density function to false alarm and hit rates for different confidence thresholds. The slope of the zROC curve equals 1 exactly when the variance of the signal and noise distributions are equal. In detection experiments, the slope is often shallower than 1, indicating a wider signal distribution. Indeed, in our positive control experiment (Exp. 7), the median zROC slope was 0.86 and significantly shallower than 1 (<span class="math inline">\(t(103) = -5.08\)</span>, <span class="math inline">\(p &lt; .001\)</span> for a t-test on the log-slope against zero). Measuring the slope of the zROC curve in our six pre-registered experiments, we asked whether our ‘feature-present’ distributions had higher variance than our ‘feature-absent’ distributions. We used the standardized effect size obtained from Experiment 7 as a scaling factor for the prior distribution over effect sizes, reflecting a belief that a difference in slopes should be similar in magnitude to what is observed in a detection task.</p>
<p>zROC slopes were numerically shallower than one in Experiments 1 (Q vs. O; median slope = 0.95), 3 (line tilt; median slope = 0.94), 4 (line curvature; 0.97) and 5 (cube orientation; 0.95). This was significant only in Experiment 5 (<span class="math inline">\(t(101) = -2.09\)</span>, <span class="math inline">\(p = .039\)</span>). In agreement with the results of our rcROC analysis, the zROC slope in Exp. 2 (C vs. O) was significantly higher than one, suggesting that the representation of the letter ‘O’ was more variable than that of the letter ‘C’ (median slope = 1.09; <span class="math inline">\(t(104) = 2.29\)</span>, <span class="math inline">\(p = .024\)</span>). A Bayes Factor analysis did not provide support for or against the null hypothesis for any of the six experiments (all Bayes Factors between 1/3 and 3).</p>
<p>Previous studies reported similar variance structures for these stimuli when presented in visual search arrays. For example, confidence in a vertical/tilted visual search task revealed higher variance in the representation of tilted (feature positive) compared to vertical (feature negative) stimuli <span class="citation">(Vincent, 2011)</span>. Similarly, reverse correlation analysis revealed higher variance in the representation of <em>Q</em> (feature positive) compared to <em>O</em> (feature negative) stimuli <span class="citation">(Saiki, 2008)</span>. Finally, and in agreement with our results, variance in the representation of <em>O</em> (feature negative) was found to be higher than in the representation of <em>C</em> (feature positive) <span class="citation">(Dosher, Han, &amp; Lu, 2004)</span>. Note that for the case of line tilt and <em>Q</em> vs. <em>O</em>, finding a high-variance target among low-variance distractors is easier than finding a low-variance target among high-variance distractors. However, the opposite is true for <em>C</em> vs. <em>O</em>, where a low-variance target (<em>C</em>) renders the search easier. This last observation challenges the suggestion that variance structure is the determining factor for visual search asymmetries <span class="citation">(Dosher, Han, &amp; Lu, 2004; Saiki, 2008; A. Treisman &amp; Gormican, 1988; Vincent, 2011)</span>.</p>
</div>
<div id="inter-subject-correlations" class="section level4 unnumbered">
<h4>Inter-subject correlations</h4>
<p>Across experiments, asymmetry in mean confidence (Hypothesis 1) and in response time (Hypothesis 4) were mostly aligned. This is consistent with previous reports of a negative correlation between response times and confidence across trials within participants <span class="citation">(Calder-Travis, Charles, Bogacz, &amp; Yeung, 2020; Henmon, 1911; Moran, Teodorescu, &amp; Usher, 2015; Pleskac &amp; Busemeyer, 2010)</span>. To test if this was the case across participants too, and not only across experiments, we fitted a mixed-effects regression model to data from all seven experiments with experiment as a random effect (<span class="math inline">\(\Delta RT \sim \Delta conf+(1+\Delta conf|exp)\)</span>). The association between confidence and RT effects was significant in this model (<span class="math inline">\(p&lt;0.001\)</span>; see Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-correlations-fig">5.7</a>; upper panel). In contrast, metacognitive asymmetry (difference between the area under the rcROC curves, controlling for response bias) was not significantly associated with asymmetry in either confidence ratings (<span class="math inline">\(p=0.41\)</span>; see Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-correlations-fig">5.7</a>; lower panel) or reaction time (<span class="math inline">\(p=0.54\)</span>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:asymmetry-correlations-fig"></span>
<img src="figure/asymmetry/correlations.png" alt="Upper panel: Difference in mean confidence between S1 and S2 responses plotted against differnce in mean response time between S1 and S2 responses across the seven experiments. Lower panel: Difference in mean confidence between S1 and S2 responses plotted against difference in metacognitive sensitivity, controlling for response bias, across the seven experiments. Semi-transparent circles represent individual subjects. Opaque circles are the means for each of the seven experiments, across participants. Lines indicate the best-fitting linear regression line for experiments 1-7." width="100%" />
<p class="caption">
Figure 5.7: Upper panel: Difference in mean confidence between S1 and S2 responses plotted against differnce in mean response time between S1 and S2 responses across the seven experiments. Lower panel: Difference in mean confidence between S1 and S2 responses plotted against difference in metacognitive sensitivity, controlling for response bias, across the seven experiments. Semi-transparent circles represent individual subjects. Opaque circles are the means for each of the seven experiments, across participants. Lines indicate the best-fitting linear regression line for experiments 1-7.
</p>
</div>
</div>
</div>
</div>
<div id="discussion-4" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Discussion</h2>
<p>In perceptual detection, judgments about the presence or absence of a target stimulus differ in several ways. First, participants are more confident in stimulus presence than in stimulus absence <span class="citation">(Kellij, Fahrenfort, Lau, Peters, &amp; Odegaard, 2018; e.g., Meuwese, Loon, Lamme, &amp; Fahrenfort, 2014)</span>. Second, confidence ratings in judgments of stimulus presence are more aligned with objective accuracy <span class="citation">(Kellij, Fahrenfort, Lau, Peters, &amp; Odegaard, 2018; Mazor, Friston, &amp; Fleming, 2020; Meuwese, Loon, Lamme, &amp; Fahrenfort, 2014)</span>. Finally, participants are faster to report stimulus presence <span class="citation">(Mazor, Friston, &amp; Fleming, 2020)</span>. In our positive control detection experiment (Experiment 7) we replicated these detection asymmetries. We found a mean difference of 20% confidence between decisions about the presence or absence of a grating, a metacognitive asymmetry of 0.07 in AUC units (ranging from 0 to 1), and a median difference of 124 milliseconds in response time between reports of target presence and absence.</p>
<p>In six pre-registered experiments, we focused on these three behavioural signatures of decisions about the presence and absence of a stimulus, and asked whether they extend to discrimination tasks where stimuli are distinct in the presence or absence of sub-stimulus features such as the presence of an additional line in a letter, the curvature of a line, or more abstractly, the presence of a surprising default-violating signal. Our six stimulus pairs have been shown in previous studies to produce asymmetries in visual search, potentially reflecting differences in the processing of presences and absences of visual features, and of default-complying versus default-violating stimuli. If detection asymmetries also reflect differences in the abstract processing of presences and absences, or of default-complying versus default-violating sensory input, one would expect to find detection-like asymmetries in response time, confidence, and metacognitive sensitivity for discrimination between stimuli that produce asymmetries in a visual search task.</p>
<p>Starting from the end, Experiments 5 and 6 provide evidence against the proposal that asymmetries in confidence, reaction time and metacognitive sensitivity emerge for default-violating signals at all levels of representation. Stimulus pairs in Exp. 5 (cube orientation) and 6 (letter inversion) produced rcROC curves that were more consistent with the absence of metacognitive asymmetry than with our prior distribution on effect sizes (see section <a href="5-ch-asymmetry.html#analysis-plan">5.2.4</a> for the specifics of our Bayesian hypothesis testing, including our prior on effect sizes). Given that these stimuli have been shown to produce reliable asymmetries in visual search <span class="citation">(U. Frith, 1974; Malinowski &amp; Hübner, 2001; Shen &amp; Reingold, 2001; Von Grünau &amp; Dubé, 1994; Wang, Cavanagh, &amp; Green, 1994)</span>, we can safely conclude that not all default violations that produce an asymmetry in visual search also produce an asymmetry in metacognitive sensitivity.</p>
<p>Moreover, in Exp. 6, default-complying <em>N</em> responses were faster, and accompanied by higher levels of subjective confidence, than default-violating flipped-<em>N</em> responses. This is in contrast to our prediction of a processing advantage for default-violating signals, and in line with previous reports of a processing advantage for familiar over unfamiliar stimuli in the context of face perception and reading. For example, in a breaking continuous flash suppression (bCFS) paradigm, inverted faces took longer to break into awareness than upright faces <span class="citation">(Stein &amp; Peelen, 2021)</span>. A similar processing advantage for familiar stimuli has been documented for the perception of words <span class="citation">(Albonico, Furubacke, Barton, &amp; Oruc, 2018)</span> and Chinese letters <span class="citation">(Xue, Chen, Jin, &amp; Dong, 2006)</span>. One possibility is that the perception of highly familiar stimuli such as letters and faces is supported by specific expert brain systems, affording a processing advantage beyond the general superior processing of default-violating signals <span class="citation">(Xue, Chen, Jin, &amp; Dong, 2006; Yovel &amp; Kanwisher, 2005)</span>. Indeed, Exp. 6 was the only experiment in which we observed a processing advantage for familiar over unfamiliar stimuli.</p>
<p>Next, in Experiments 3 and 4 we looked at two features that have a global effect on stimulus appearance: tilt and curvature. Based on visual search asymmetries, <span class="citation">A. Treisman &amp; Gormican (1988)</span> proposed that tilt and curvature are represented as positive features in the visual system. This takes us one step closer to typical detection experiments: participants now detect the presence or absence of a basic visual feature. In agreement with our Hypotheses 1 and 4, participants were more confident in identifying tilted and curved lines (mean differences of 0.12 and 0.12 on a 0-1 confidence scale), and were faster in giving these responses (mean differences of 67.67 and 50.57 ms). However, we did not find evidence for or against a metacognitive asymmetry for these global visual features.</p>
<p>Our strongest candidate for a stimulus pair for which we expected to find a presence-absence asymmetry was <em>Q</em> vs. <em>O</em> (Exp. 1). The difference between these two letters is the presence of an additional line stroke: a concrete stimulus part that is localized in space and is independent of the rest of the stimulus. Theoretically, participants could approach this task as a detection task: ignore the common denominator (<em>O</em>) and focus on the presence or absence of the distinctive feature (‘,’). As we hypothesized, participants were more confident in their <em>Q</em> responses (mean difference of 0.11 on a 0-1 confidence scale). Participants were also faster in their <em>Q</em> responses (median difference of 37 ms). However, unlike stimulus-level detection, a small difference of 0.04 units in the area under the rcROC ROC curves was not different to what is expected based on a null SDT model.</p>
<p>Finally, In Experiment 2 we looked at discrimination between <em>C</em> and <em>O</em>s based on evidence from visual search that open edges are represented as a positive feature in the visual system <span class="citation">(Takeda &amp; Yagi, 2000; A. Treisman &amp; Gormican, 1988; A. Treisman &amp; Souther, 1985)</span>. As we hypothesized, <em>C</em> responses were accompanied by higher levels of subjective confidence (mean difference of 0.05 on a 0-1 confidence scale). However, in striking contrast to our original hypothesis, metacognitive sensitivity was <em>lower</em> for <em>C</em> responses (mean difference of 0.05 AUC units), even when controlling for response bias. This result strongly supports different underlying mechanisms behind search and metacognitive asymmetries. Furthermore, the results of Experiment 2 suggest distinct factors mediate the processing advantage for presence over absence (as reflected in shorter response times and higher confidence for <em>C</em> responses), and the metacognitive asymmetry between presence and absence (as reflected in improved metacognitive sensitivity for <em>O</em> responses).</p>
<p><em>C</em> and <em>O</em> are unique in that the difference between them corresponds to two contrasting notions of presence and absence. On the one hand, <em>C</em> is marked by the presence of one additional feature - open edges <span class="citation">(A. Treisman &amp; Gormican, 1988; A. Treisman &amp; Souther, 1985)</span>. On the other hand, it is marked by the absence of a piece: there is simply less of it relative to <em>O</em>. These two notions of presence and absence are typically coupled in detection. For example, the presence of a grating on a screen corresponds to the presence of additional features (such as orientation, contrast, and phase) as well as of more ‘visual stuff,’ relative to the blank background. A compelling interpretation of the results of Exp. 2 is that it is the presence or absence of visual features such as open edges that is driving the difference in confidence and response time, whereas a more quantitative notion of presence or absence (the amount of ‘visual stuff’ presented) is driving the metacognitive asymmetry between these two responses. We note however that based on this interpretation, we would expect a metacognitive sensitivity to operate also in Experiment 1, where <em>O</em> is missing a piece relative to <em>Q</em>. As described above, Experiment 1 provided no evidence for such a metacognitive asymmetry beyond what is expected from an equal-variance signal-detection model.</p>
<p>Notably, not one of the six pre-registered experiments produced a metacognitive asymmetry in the expected direction. This was in contrast to Experiment 7 (grating vs. noise), where metacognitive sensitivity for reporting noise was lower than for reporting a noisy grating (with a difference of 0.07 auROC2 units, <span class="math inline">\(\mathrm{BF}_{\textrm{10}} = 31.40\)</span>). Positive control Experiment 7 was also the only experiment in which we found higher variance for stimulus S1 than for stimulus S2 (with a median variance ratio of 0.86). These two observations are likely to be related: across participants, metacognitive asymmetry and variance ratio were highly correlated (<span class="math inline">\(r = .64\)</span>, 95% CI <span class="math inline">\([.51\)</span>, <span class="math inline">\(.74]\)</span>, <span class="math inline">\(t(102) = 8.42\)</span>, <span class="math inline">\(p &lt; .001\)</span>). Indeed, previous theoretical work has pointed out that response-dependent asymmetries in metacognition may be driven by an underlying unequal-variance SDT model, and, vice-versa, that findings of unequal variance might be due to a response-dependent metacognitive asymmetry. These two perspectives are interchangeable <span class="citation">(Maniscalco &amp; Lau, 2014)</span>. However, a correlation between metacognitive asymmetry and variance structure, both estimated from confidence ratings, is not a satisfactory answer for <em>why</em> noise and gratings should exhibit a unique asymmetry in metacognitive sensitivity, or in variance structure. More theoretical and experimental work is needed to identify the sources of this asymmetry, perhaps focusing on the role of stimulus complexity and perceptual uncertainty as potential drivers of this effect.</p>
<p>When interpreting our findings in a broader context, it is useful to note that in all six experiments we used backward masking for controlling the visibility level of our stimuli. Different visibility manipulations have been shown to affect detection metacognitive sensitivity in different ways. For example, whereas metacognitive sensitivity in detection ‘no’ responses is at chance when backward masking is used, it is significantly higher than chance when the attentional blink is used to control stimulus visibility <span class="citation">(Kanai, Walsh, &amp; Tseng, 2010)</span>. Similarly, phase scrambling but not attentional blink produces a metacognitive advantage for ‘yes’ responses <span class="citation">(Kellij, Fahrenfort, Lau, Peters, &amp; Odegaard, 2018)</span>. While our positive control (Exp. 7) produced a reliable metacognitive asymmetry between judgments of target presence and absence, it was also the only experiment where stimulus visibility was controlled with low contrast, in addition to backward masking (for the purpose of compatibility with previous experiments; see Fig. <a href="5-ch-asymmetry.html#fig:asymmetry-rcROC7">5.6</a>). Based on our findings alone, we cannot rule out the possibility that using other visibility manipulations may reveal metacognitive asymmetries for the presence or absence of abstract default violations. Furthermore, it is possible that some of the observed asymmetries for low-level features may reflect asymmetries in the joint perception of target stimulus and backward mask, rather than in the perception of the target stimulus by itself <span class="citation">(Jannati &amp; Di Lollo, 2012; Kahneman, 1968)</span>.</p>
<p>Together, our findings weigh against our original proposal that metacognitive asymmetries in perceptual detection are a signature of higher-order default reasoning. Unlike search asymmetries that extend to abstract levels of representations such as familiarity <span class="citation">(Wang, Cavanagh, &amp; Green, 1994; J. M. Wolfe, 2001)</span> and even social features such as ethnicity and gender <span class="citation">(Gandolfo &amp; Downing, 2020; Levin &amp; Angelone, 2001)</span>, metacognitive asymmetries in visual discrimination are grounded in concrete visual processing. Furthermore, we provide evidence for a dissociation between asymmetries in metacognition and in response time and confidence, where the latter is linked to activation of basic feature-detectors, for example of orientation, open ends, or curvature.</p>
</div>
<div id="conclusion-1" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Conclusion</h2>
<p>In a set of six experiments, we sought to test the proposal that a metacognitive asymmetry between the representation of stimulus presence and absence is one instance of a more general asymmetry between the representation of default states and default-violating surprises. Our findings provide evidence against this idea. A metacognitive asymmetry was not observed in near-threshold discrimination between stimulus pairs that differ in their alignment with default expectations. This was the case even in pairs that showed substantial asymmetries in response time and overall confidence levels. Results from our pre-registered set of analyses are most consistent with a narrow interpretation of the presence/absence metacognitive asymmetry in visual detection, that is limited to concrete, spatially localized presences. Furthermore, a metacognitive asymmetry between <em>C</em>s and <em>O</em>s in the opposite direction to what is observed in visual search indicates that different cognitive and perceptual mechanisms underlie these two apparently similar phenomena.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4-ch-fMRI.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="general-discussion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
