<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>A Signal Detection Theory | Self-Modeling in Inference about Absence</title>
  <meta name="description" content="A Signal Detection Theory | Self-Modeling in Inference about Absence" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="A Signal Detection Theory | Self-Modeling in Inference about Absence" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Signal Detection Theory | Self-Modeling in Inference about Absence" />
  
  
  

<meta name="author" content="Matan Mazor" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="general-discussion.html"/>
<link rel="next" href="B-supp-materials-for-ch-2.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminary Content</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#preface"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i>Abstract</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="0.1" data-path="introduction.html"><a href="introduction.html#inference-about-absence"><i class="fa fa-check"></i><b>0.1</b> Inference about absence</a></li>
<li class="chapter" data-level="0.2" data-path="introduction.html"><a href="introduction.html#formalabsence"><i class="fa fa-check"></i><b>0.2</b> Probabilistic reasoning, criterion setting, and self knowledge</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#symmetrical-definition"><i class="fa fa-check"></i>Symmetrical definition:</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#dissymmetrical-definition"><i class="fa fa-check"></i>Dissymmetrical definition:</a></li>
<li class="chapter" data-level="0.2.1" data-path="introduction.html"><a href="introduction.html#second-order-cognition"><i class="fa fa-check"></i><b>0.2.1</b> Second-order cognition</a></li>
<li class="chapter" data-level="0.2.2" data-path="introduction.html"><a href="introduction.html#detectionmodels"><i class="fa fa-check"></i><b>0.2.2</b> Computational models of detection</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#htm"><i class="fa fa-check"></i>The High-Threshold model</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#sdt"><i class="fa fa-check"></i>Signal Detection Theory</a></li>
</ul></li>
<li class="chapter" data-level="0.3" data-path="introduction.html"><a href="introduction.html#detection-i-would-have-noticed-it"><i class="fa fa-check"></i><b>0.3</b> Detection: “I would have noticed it”</a></li>
<li class="chapter" data-level="0.4" data-path="introduction.html"><a href="introduction.html#intro:search"><i class="fa fa-check"></i><b>0.4</b> Visual search: “I would have found it”</a></li>
<li class="chapter" data-level="0.5" data-path="introduction.html"><a href="introduction.html#memory-i-would-have-remembered-it"><i class="fa fa-check"></i><b>0.5</b> Memory: “I would have remembered it”</a></li>
<li class="chapter" data-level="0.6" data-path="introduction.html"><a href="introduction.html#the-development-of-a-self-model"><i class="fa fa-check"></i><b>0.6</b> The development of a self-model</a></li>
<li class="chapter" data-level="0.7" data-path="introduction.html"><a href="introduction.html#this-thesis"><i class="fa fa-check"></i><b>0.7</b> This thesis</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-ch-search.html"><a href="1-ch-search.html"><i class="fa fa-check"></i><b>1</b> Zero-shot search termination reveals a dissociation between implicit and explicit metacognitive knowledge</a><ul>
<li class="chapter" data-level="1.1" data-path="1-ch-search.html"><a href="1-ch-search.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="1-ch-search.html"><a href="1-ch-search.html#experiment-1"><i class="fa fa-check"></i><b>1.2</b> Experiment 1</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-ch-search.html"><a href="1-ch-search.html#participants"><i class="fa fa-check"></i><b>1.2.1</b> Participants</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-ch-search.html"><a href="1-ch-search.html#procedure"><i class="fa fa-check"></i><b>1.2.2</b> Procedure</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-ch-search.html"><a href="1-ch-search.html#data-analysis"><i class="fa fa-check"></i><b>1.2.3</b> Data analysis</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-ch-search.html"><a href="1-ch-search.html#results"><i class="fa fa-check"></i><b>1.2.4</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-ch-search.html"><a href="1-ch-search.html#experiment-2"><i class="fa fa-check"></i><b>1.3</b> Experiment 2</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-ch-search.html"><a href="1-ch-search.html#participants-1"><i class="fa fa-check"></i><b>1.3.1</b> Participants</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-ch-search.html"><a href="1-ch-search.html#procedure-1"><i class="fa fa-check"></i><b>1.3.2</b> Procedure</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-ch-search.html"><a href="1-ch-search.html#results-1"><i class="fa fa-check"></i><b>1.3.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-ch-search.html"><a href="1-ch-search.html#discussion"><i class="fa fa-check"></i><b>1.4</b> Discussion</a><ul>
<li class="chapter" data-level="1.4.1" data-path="1-ch-search.html"><a href="1-ch-search.html#is-implicit-metacognitive-knowledge-metacognitive"><i class="fa fa-check"></i><b>1.4.1</b> Is implicit metacognitive knowledge metacognitive?</a></li>
<li class="chapter" data-level="1.4.2" data-path="1-ch-search.html"><a href="1-ch-search.html#inference-about-absence-as-a-tool-for-studying-implicit-self-knowledge"><i class="fa fa-check"></i><b>1.4.2</b> Inference about absence as a tool for studying implicit self knowledge</a></li>
<li class="chapter" data-level="1.4.3" data-path="1-ch-search.html"><a href="1-ch-search.html#conclusion"><i class="fa fa-check"></i><b>1.4.3</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-ch-RC.html"><a href="2-ch-RC.html"><i class="fa fa-check"></i><b>2</b> Paradoxical evidence weightings in confidence judgments for detection and discrimination</a><ul>
<li class="chapter" data-level="2.1" data-path="2-ch-RC.html"><a href="2-ch-RC.html#introduction-2"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="2-ch-RC.html"><a href="2-ch-RC.html#experiment-1-1"><i class="fa fa-check"></i><b>2.2</b> Experiment 1</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-ch-RC.html"><a href="2-ch-RC.html#methods"><i class="fa fa-check"></i><b>2.2.1</b> Methods</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-ch-RC.html"><a href="2-ch-RC.html#analysis"><i class="fa fa-check"></i><b>2.2.2</b> Analysis</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-ch-RC.html"><a href="2-ch-RC.html#results-2"><i class="fa fa-check"></i><b>2.2.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-ch-RC.html"><a href="2-ch-RC.html#experiment-2-1"><i class="fa fa-check"></i><b>2.3</b> Experiment 2</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-ch-RC.html"><a href="2-ch-RC.html#methods-1"><i class="fa fa-check"></i><b>2.3.1</b> Methods</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-ch-RC.html"><a href="2-ch-RC.html#results-3"><i class="fa fa-check"></i><b>2.3.2</b> Results</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-ch-RC.html"><a href="2-ch-RC.html#detection-signal-trials-1"><i class="fa fa-check"></i><b>2.3.3</b> Detection signal trials</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-ch-RC.html"><a href="2-ch-RC.html#discussion-1"><i class="fa fa-check"></i><b>2.4</b> Discussion</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-ch-RC.html"><a href="2-ch-RC.html#model-1-a-rational-agent-symmetric-evidence-structure"><i class="fa fa-check"></i><b>2.4.1</b> Model 1: a rational agent + symmetric evidence structure</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-ch-RC.html"><a href="2-ch-RC.html#model-2-a-rational-agent-symmetric-evidence-structure"><i class="fa fa-check"></i><b>2.4.2</b> Model 2: a rational agent + symmetric evidence structure</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-ch-RC.html"><a href="2-ch-RC.html#model-3-confidence-decision-cross"><i class="fa fa-check"></i><b>2.4.3</b> Model 3: confidence decision cross</a></li>
<li class="chapter" data-level="2.4.4" data-path="2-ch-RC.html"><a href="2-ch-RC.html#evidence-for-absence"><i class="fa fa-check"></i><b>2.4.4</b> Evidence for absence</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><i class="fa fa-check"></i><b>3</b> Distinct neural contributions to metacognition for detecting (but not discriminating) visual stimuli</a><ul>
<li class="chapter" data-level="3.1" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#introduction-3"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#methods-and-materials"><i class="fa fa-check"></i><b>3.2</b> Methods and Materials</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#participants-4"><i class="fa fa-check"></i><b>3.2.1</b> Participants</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#design-and-procedure"><i class="fa fa-check"></i><b>3.2.2</b> Design and procedure</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#scanning-parameters"><i class="fa fa-check"></i><b>3.2.3</b> Scanning parameters</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#analysis-1"><i class="fa fa-check"></i><b>3.2.4</b> Analysis</a></li>
<li class="chapter" data-level="3.2.5" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#exclusion-criteria"><i class="fa fa-check"></i><b>3.2.5</b> Exclusion criteria</a></li>
<li class="chapter" data-level="3.2.6" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#response-conditional-type-ii-roc-curves"><i class="fa fa-check"></i><b>3.2.6</b> Response conditional type-II ROC curves</a></li>
<li class="chapter" data-level="3.2.7" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#imaging-analysis"><i class="fa fa-check"></i><b>3.2.7</b> Imaging analysis</a></li>
<li class="chapter" data-level="3.2.8" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#statistical-inference-1"><i class="fa fa-check"></i><b>3.2.8</b> Statistical inference</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#results-4"><i class="fa fa-check"></i><b>3.3</b> Results</a></li>
<li class="chapter" data-level="3.4" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#behavioural-results"><i class="fa fa-check"></i><b>3.4</b> Behavioural results</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#imaging-results"><i class="fa fa-check"></i><b>3.4.1</b> Imaging results</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#computational-models"><i class="fa fa-check"></i><b>3.4.2</b> Computational models</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html"><a href="3-distinct-neural-contributions-to-metacognition-for-detecting-but-not-discriminating-visual-stimuli.html#discussion-2"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html"><i class="fa fa-check"></i><b>4</b> Prospective search time estimates for unseen displays reveal a rich intuitive theory of visual search</a><ul>
<li class="chapter" data-level="4.1" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#introduction-4"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#experiments-1-and-2-shape-orientation-and-color"><i class="fa fa-check"></i><b>4.2</b> Experiments 1 and 2: shape, orientation, and color</a><ul>
<li class="chapter" data-level="4.2.1" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#participants-5"><i class="fa fa-check"></i><b>4.2.1</b> Participants</a></li>
<li class="chapter" data-level="4.2.2" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#procedure-2"><i class="fa fa-check"></i><b>4.2.2</b> Procedure</a></li>
<li class="chapter" data-level="4.2.3" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#results-5"><i class="fa fa-check"></i><b>4.2.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#experiments-3-and-4-complex-unfamiliar-stimuli"><i class="fa fa-check"></i><b>4.3</b> Experiments 3 and 4: complex, unfamiliar stimuli</a><ul>
<li class="chapter" data-level="4.3.1" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#participants-6"><i class="fa fa-check"></i><b>4.3.1</b> Participants</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#procedure-3"><i class="fa fa-check"></i><b>4.3.2</b> Procedure</a></li>
<li class="chapter" data-level="4.3.3" data-path="4-ch-MVS.html"><a href="4-ch-MVS.html#results-6"><i class="fa fa-check"></i><b>4.3.3</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="general-discussion.html"><a href="general-discussion.html"><i class="fa fa-check"></i>General Discussion</a><ul>
<li class="chapter" data-level="4.4" data-path="general-discussion.html"><a href="general-discussion.html#summary-of-results"><i class="fa fa-check"></i><b>4.4</b> Summary of results</a></li>
<li class="chapter" data-level="4.5" data-path="general-discussion.html"><a href="general-discussion.html#what-i-didnt-find"><i class="fa fa-check"></i><b>4.5</b> What I didn’t find</a><ul>
<li class="chapter" data-level="4.5.1" data-path="general-discussion.html"><a href="general-discussion.html#chapter-1-no-correlation-with-explicit-metacognition"><i class="fa fa-check"></i><b>4.5.1</b> Chapter 1: no correlation with explicit metacognition</a></li>
<li class="chapter" data-level="4.5.2" data-path="general-discussion.html"><a href="general-discussion.html#chapter-2-no-effect-of-confidence-in-signal-presence"><i class="fa fa-check"></i><b>4.5.2</b> Chapter 2: no effect of confidence in signal presence</a></li>
<li class="chapter" data-level="4.5.3" data-path="general-discussion.html"><a href="general-discussion.html#chapter-3-small-differences-in-brain-activity-between-inference-about-absence-and-presence"><i class="fa fa-check"></i><b>4.5.3</b> Chapter 3: small differences in brain activity between inference about absence and presence</a></li>
<li class="chapter" data-level="4.5.4" data-path="general-discussion.html"><a href="general-discussion.html#section"><i class="fa fa-check"></i><b>4.5.4</b> </a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="general-discussion.html"><a href="general-discussion.html#future-directions"><i class="fa fa-check"></i><b>4.6</b> Future directions</a><ul>
<li class="chapter" data-level="4.6.1" data-path="general-discussion.html"><a href="general-discussion.html#failures-of-a-self-model"><i class="fa fa-check"></i><b>4.6.1</b> Failures of a self-model</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="general-discussion.html"><a href="general-discussion.html#conclusion-1"><i class="fa fa-check"></i><b>4.7</b> Conclusion</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html"><i class="fa fa-check"></i><b>A</b> Signal Detection Theory</a><ul>
<li class="chapter" data-level="A.1" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html#app1:ROC"><i class="fa fa-check"></i><b>A.1</b> ROC and zROC curves</a></li>
<li class="chapter" data-level="A.2" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html#app1:uvSDT"><i class="fa fa-check"></i><b>A.2</b> Unequal-variance (uv) SDT</a></li>
<li class="chapter" data-level="A.3" data-path="A-app1-SDT.html"><a href="A-app1-SDT.html#app1:mc"><i class="fa fa-check"></i><b>A.3</b> SDT Measures for Metacognition</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-supp-materials-for-ch-2.html"><a href="B-supp-materials-for-ch-2.html"><i class="fa fa-check"></i><b>B</b> Supp. materials for ch. 2</a><ul>
<li class="chapter" data-level="B.1" data-path="B-supp-materials-for-ch-2.html"><a href="B-supp-materials-for-ch-2.html#app2:PDRC"><i class="fa fa-check"></i><b>B.1</b> Pseudo-discrimination analysis</a><ul>
<li class="chapter" data-level="B.1.1" data-path="B-supp-materials-for-ch-2.html"><a href="B-supp-materials-for-ch-2.html#exp.-1"><i class="fa fa-check"></i><b>B.1.1</b> Exp. 1</a></li>
<li class="chapter" data-level="B.1.2" data-path="B-supp-materials-for-ch-2.html"><a href="B-supp-materials-for-ch-2.html#exp.-2"><i class="fa fa-check"></i><b>B.1.2</b> Exp. 2</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="B-supp-materials-for-ch-2.html"><a href="B-supp-materials-for-ch-2.html#app2:simulation"><i class="fa fa-check"></i><b>B.2</b> Unequal-variance model</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-supp-materials-for-ch-2.html"><a href="B-supp-materials-for-ch-2.html#discrimination"><i class="fa fa-check"></i><b>B.2.1</b> Discrimination</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-supp-materials-for-ch-2.html"><a href="B-supp-materials-for-ch-2.html#detection-1"><i class="fa fa-check"></i><b>B.2.2</b> Detection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html"><i class="fa fa-check"></i><b>C</b> Supp. materials for ch. 3</a><ul>
<li class="chapter" data-level="C.1" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:buttonpresses"><i class="fa fa-check"></i><b>C.1</b> Confidence button presses</a></li>
<li class="chapter" data-level="C.2" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:zROC"><i class="fa fa-check"></i><b>C.2</b> zROC curves</a></li>
<li class="chapter" data-level="C.3" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:GC-DM"><i class="fa fa-check"></i><b>C.3</b> Global confidence design matrix</a></li>
<li class="chapter" data-level="C.4" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:ROIconf"><i class="fa fa-check"></i><b>C.4</b> Effect of confidence in our pre-specified ROIs</a></li>
<li class="chapter" data-level="C.5" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:varianceRat"><i class="fa fa-check"></i><b>C.5</b> SDT variance ratio correlation with the quadratic confidence effect</a></li>
<li class="chapter" data-level="C.6" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:efficiency"><i class="fa fa-check"></i><b>C.6</b> Correlation of metacognitive efficiency with linear and quadratic confidence effects</a></li>
<li class="chapter" data-level="C.7" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:cross"><i class="fa fa-check"></i><b>C.7</b> Confidence-decision cross classification</a></li>
<li class="chapter" data-level="C.8" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:SDT"><i class="fa fa-check"></i><b>C.8</b> Static Signal Detection Theory</a><ul>
<li class="chapter" data-level="C.8.1" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#discrimination-1"><i class="fa fa-check"></i><b>C.8.1</b> Discrimination</a></li>
<li class="chapter" data-level="C.8.2" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#detection-2"><i class="fa fa-check"></i><b>C.8.2</b> Detection</a></li>
</ul></li>
<li class="chapter" data-level="C.9" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:Dynamic"><i class="fa fa-check"></i><b>C.9</b> Dynamic Criterion</a><ul>
<li class="chapter" data-level="C.9.1" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#discrimination-2"><i class="fa fa-check"></i><b>C.9.1</b> Discrimination</a></li>
<li class="chapter" data-level="C.9.2" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#detection-3"><i class="fa fa-check"></i><b>C.9.2</b> Detection</a></li>
</ul></li>
<li class="chapter" data-level="C.10" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#app3:Monitoring"><i class="fa fa-check"></i><b>C.10</b> Attention Monitoring</a><ul>
<li class="chapter" data-level="C.10.1" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#discrimination-3"><i class="fa fa-check"></i><b>C.10.1</b> Discrimination</a></li>
<li class="chapter" data-level="C.10.2" data-path="C-supp-materials-for-ch-3.html"><a href="C-supp-materials-for-ch-3.html#detection-4"><i class="fa fa-check"></i><b>C.10.2</b> Detection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Self-Modeling in Inference about Absence</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="app1:SDT" class="section level1">
<h1><span class="header-section-number">A</span> Signal Detection Theory</h1>
<p>“Signal Detection Theory” is a conceptual framework for the description of decision making between two alternatives in the presence of uncertainty. Examples include deciding whether a presented word has been studied before or not, to which of two groups does a noisy stimulus belong, or whether a stimulus was presented on the screen or not <span class="citation">(Stanislaw &amp; Todorov, 1999; Tanner Jr &amp; Swets, 1954)</span>. Under this framework, on each experimental trial a “decision variable” is sampled from one of two distributions. I will refer to these distributions here as the <em>signal</em> and <em>noise</em> distributions, although depending on context they can have different labels, such as <em>old</em> and <em>new</em> distributions in recognition memory task or <em>right</em> and <em>left</em> in a movement discrimination task. On trials in which the decision variable exceeds a criterion <span class="math inline">\(c\)</span>, a ‘yes’ response is executed, otherwise a ‘no’ response is executed (see Fig. <a href="A-app1-SDT.html#fig:app1-SDT">A.1</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:app1-SDT"></span>
<img src="figure/app-SDT/SDT.png" alt="Distribution of the decision variable across noise and signal trials, showing *d'*, *c*, and the likelihoods. Figure from @stanislaw1999calculation" width="70%" />
<p class="caption">
Figure A.1: Distribution of the decision variable across noise and signal trials, showing <em>d’</em>, <em>c</em>, and the likelihoods. Figure from <span class="citation">Stanislaw &amp; Todorov (1999)</span>
</p>
</div>
<p>Given the noisiness of the incoming input, some signal trials will result in a ‘no’ response and some noise trials will result in a ‘yes’ response. This makes a total of four groups of trials that can be ordered in a two by two table:</p>
<table>
<caption><span id="tab:app1SDT">Table A.1: </span> SDT response classification.</caption>
<thead>
<tr class="header">
<th>response</th>
<th>signal</th>
<th>noise</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>‘yes’</td>
<td>hit</td>
<td>false alarm</td>
</tr>
<tr class="even">
<td>‘no’</td>
<td>miss</td>
<td>correct rejection</td>
</tr>
</tbody>
</table>
<p>Two conditional probabilities are sufficient to provide a full description of the behaviour profile of a participant, namely <span class="math inline">\(p(yes|Signal)\)</span> (the ‘hit rate’), and <span class="math inline">\(p(yes|Noise)\)</span> (the ‘false alarm rate’). SDT makes it possible to translate these two probabilities to properties of the signal and noise distributions and their positioning with respect to the decision criterion. The parameter <span class="math inline">\(d&#39;\)</span> represents the distance between the two distributions in standard deviations. Under the assumption of equal variance of the two distributions <span class="math inline">\(d&#39;\)</span> can be approximated as <span class="math inline">\(\hat{d&#39;}=Z(h)-Z(f)\)</span>, with <span class="math inline">\(Z\)</span> representing the inverse cumulative normal distribution. The parameter <span class="math inline">\(\lambda\)</span> stands for the position of the criterion relative to the mean of the noise distribution, and can be approximated as <span class="math inline">\(\hat{\lambda}=-Z(f)\)</span>.</p>
<div id="app1:ROC" class="section level2">
<h2><span class="header-section-number">A.1</span> ROC and zROC curves</h2>
<p>The false alarm and hit rates are often insufficient to provide a full description of a system. For example, they are not sufficient to determine the ratio between the variance terms of the two distributions, and therefore to decide if the equal variance assumption holds. To obtain a fuller picture, false alarm and hit rates can be recorded under different settings of the decision criterion. One way to experimentally shift the criterion is by manipulation of the task incentive structure. For example, in order to encourage participants to make more ‘no’ responses, rewards for correct rejections can be set higher than rewards for hits. Alternatively, confidence ratings can be collected for every decision. The criterion can then be theoretically placed between every two possible confidence ratings, to generate a full set of false positive and hit rates.</p>
<p>A “<em>Receiver Operating Characteristic</em>” (ROC) curve is the plot of false alarm and hit rates for all possible settings of a decision criterion value. It can be approximated by plotting the false alarm and hit rates for the criterion values available by the experimental manipulation (see figure ). For a system that performs at chance, false positive and hit rates should be equal for every criterion, giving rise to an ROC that follows the identity line. The area under the ROC curve (“AUROC”) can be interpreted as the proportion of times the system will identify the stimulus in a 2AFC task where noise and signal are presented simultaneously <span class="citation">(Stanislaw &amp; Todorov, 1999)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:app1-ROC"></span>
<img src="figure/app-SDT/ROC.png" alt="Receiver Operating Characteristic (ROC) curve. Three points on the ROC curve are shown (open squares). The area under the curve, as estimated by linear extrapolation, is indicating by hatching; the true area includes the gray regions. Figure from @stanislaw1999calculation" width="60%" />
<p class="caption">
Figure A.2: Receiver Operating Characteristic (ROC) curve. Three points on the ROC curve are shown (open squares). The area under the curve, as estimated by linear extrapolation, is indicating by hatching; the true area includes the gray regions. Figure from <span class="citation">Stanislaw &amp; Todorov (1999)</span>
</p>
</div>
<p>Often it is informative to plot the inverse of the cumulative distribution for <span class="math inline">\(p(f)\)</span> and <span class="math inline">\(p(h)\)</span>, resulting in what is known as a “zROC curve” (see figure ). The zROC curve is linear when the noise and signal distributions are approximately normal. The slope of the zROC curve equals the ratio between the standard deviations of the noise and signal distributions <span class="citation">(Stanislaw &amp; Todorov, 1999)</span>. Hence, the standard equal-variance SDT model predicts a linear zROC curve with a slope of 1.</p>
<div class="figure" style="text-align: center"><span id="fig:app1-zROC"></span>
<img src="figure/app-SDT/zROC.png" alt="zROC curve" width="60%" />
<p class="caption">
Figure A.3: zROC curve
</p>
</div>
</div>
<div id="app1:uvSDT" class="section level2">
<h2><span class="header-section-number">A.2</span> Unequal-variance (uv) SDT</h2>
<p>Unequal variance (uv) SDT can be applied to settings in which one distribution is assumed to be wider. For example, in perceptual detection tasks it is plausible that the signal distribution will be wider, as every sample comprises two sources of variance: a baseline noise component that is shared with the noise distribution, and the stimulus noise that represents fluctuations in the evidence strength available in the physical stimulus. A similar pattern is typically observed in recognition memory tasks.</p>
<p>This simple change to the model has profound effects on the decision making process. Under the assumption of equal-variance, the “log likelihood-ratio” (LLR; <span class="math inline">\(log(\frac{p(x|signal)}{p(x|noise)})\)</span>) increases monotonically as a function of the decision variable, so that an optimal solution to the inference problem can rely on one decision criterion: samples to the right of the criterion are labeled as ‘signal’, and samples to its left are labeled as ‘noise’ <span class="citation">(Wickens, 2002, p. 30)</span>. The introduction of unequal variance to the SDT model makes inference more complex. Both extreme positive and extreme negative values are more likely to be drawn from the signal distribution when it is wider than the noise distribution, making a single-criterion decision rule sub-optimal. More specifically, in an unequal-variance setting, the LLR is proportional to the square of the decision variable. This means that it can be arbitrarily high for extremely positive or negative decision variables, but has a strict lower bound around the peak of the noise distribution.</p>
</div>
<div id="app1:mc" class="section level2">
<h2><span class="header-section-number">A.3</span> SDT Measures for Metacognition</h2>
<p>the ability to reliably track one’s objective performance in a perceptual or a memory task is commonly taken as a measure of one’s metacognitive ability <span class="citation">(e.g., Fleming &amp; Dolan, 2012)</span>. This ability can be quantified by asking participants for confidence judgments (“type-2 task”) following their primary decision (“type-1 task”). The match or mismatch between objective performance and confidence can then be used as a proxy for their “metacognitive sensitivity”.</p>
<p>The way this measure is extracted depends on the assumed underlying process. One potential process is a second-order SDT model, where a second variable is sampled following the type-1 decision, and this variable is then compared with an internal criterion that separates ‘confident’ responses from ‘unconfident’ responses (or a set of criteria, in the case of more than two possible confidence ratings). This variable is assumed to have higher values on average on trials in which the type-1 response was correct, similar to how the decision variable is higher on average on trials in which a signal is presented in a visual detection task (see figure <a href="A-app1-SDT.html#fig:app1-kunimoto">A.4</a>). Assuming that the two distributions of this confidence variable are normal, and assuming equal-variance, metacognitive sensitivity can then be quantified as the <span class="math inline">\(d&#39;\)</span> of the process that aims to separate between correct and incorrect responses . Alternatively, a type-2 ROC curve can be generated by plotting <span class="math inline">\(p(confidence&gt;x|incorrect)\)</span> against <span class="math inline">\(p(confidence&gt;x|correct)\)</span> for different values of x, and the area under this curve can be extracted as a measure of metacognitive sensitivity. Under these assumptions, these SDT measures have the desired properties of relative invariance of <span class="math inline">\(d&#39;\)</span> and AuROC to the positioning of the criterion and to performance level in the type-1 task <span class="citation">(Kunimoto, Miller, &amp; Pashler, 2001)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:app1-kunimoto"></span>
<img src="figure/app-SDT/kunimoto.png" alt="A second order SDT model: confidence judgments are assumed to result from a process that uses an internal variable to separate correct from incorrect responses. Figure from @kunimoto2001confidence" width="60%" />
<p class="caption">
Figure A.4: A second order SDT model: confidence judgments are assumed to result from a process that uses an internal variable to separate correct from incorrect responses. Figure from <span class="citation">Kunimoto et al. (2001)</span>
</p>
</div>
<p>However, as discussed by <span class="citation">Maniscalco &amp; Lau (2012)</span>, this approach is unwarranted if the assumed underlying process uses the decision variable itself, or some transformation of it, in the generation of the confidence rating. In such a first-order model, the distance between the signal and noise distributions <span class="math inline">\(d&#39;\)</span> will be positively correlated with the estimated distance between the hypothetical ‘correct’ and ‘incorrect’ internal distributions. To correct for this, the authors propose to extract a measure of metacognitive sensitivity (<span class="math inline">\(meta-d&#39;\)</span>) that is fitted to the conditional distribution of confidence given stimulus and response, and compare it with <span class="math inline">\(d&#39;\)</span> (for example, by taking the ratio between these the two (<span class="math inline">\(M_{ratio}=meta-d&#39;/d&#39;\)</span>). For an interactive primer on this approach, see <a href="matanmazor.shinyapps.io/sdtprimer">matanmazor.shinyapps.io/sdtprimer</a>.
<!--
If you feel it necessary to include an appendix, it goes here.
--></p>
<p>This first appendix includes all of the R chunks of code that were hidden throughout the document (using the <code>include = FALSE</code> chunk tag) to help with readibility and/or setup.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="general-discussion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="B-supp-materials-for-ch-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
